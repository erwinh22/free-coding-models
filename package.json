{
  "name": "nimping",
  "version": "0.1.0",
  "description": "Find the fastest NVIDIA NIM coding models in seconds â€” ping 44 free LLM models optimized for code, pick the best one for OpenCode, Cursor, or any AI coding assistant.",
  "keywords": [
    "nvidia",
    "nim",
    "llm",
    "cli",
    "ai",
    "models",
    "benchmark",
    "latency",
    "availability",
    "deepseek",
    "qwen",
    "llama",
    "mistral",
    "glm",
    "kimi",
    "gpt",
    "chatgpt",
    "openai",
    "api"
  ],
  "homepage": "https://github.com/vava-nessa/nimping#readme",
  "bugs": {
    "url": "https://github.com/vava-nessa/nimping/issues"
  },
  "repository": {
    "type": "git",
    "url": "git+https://github.com/vava-nessa/nimping.git"
  },
  "license": "MIT",
  "author": "vava",
  "type": "module",
  "main": "bin/nimping.js",
  "bin": {
    "nimping": "./bin/nimping.js"
  },
  "files": [
    "bin/",
    "README.md",
    "LICENSE"
  ],
  "scripts": {
    "start": "node bin/nimping.js"
  },
  "dependencies": {
    "chalk": "^5.4.1",
    "nimping": "^0.1.0"
  },
  "engines": {
    "node": ">=18.0.0"
  }
}
