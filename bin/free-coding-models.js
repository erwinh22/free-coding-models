#!/usr/bin/env node
/**
 * @file free-coding-models.js
 * @description Live terminal availability checker for coding LLM models with OpenCode & OpenClaw integration.
 *
 * @details
 *   This CLI tool discovers and benchmarks language models optimized for coding.
 *   It runs in an alternate screen buffer, pings all models in parallel, re-pings successful ones
 *   multiple times for reliable latency measurements, and prints a clean final table.
 *   During benchmarking, users can navigate with arrow keys and press Enter to act on the selected model.
 *
 *   ğŸ¯ Key features:
 *   - Parallel pings across all models with animated real-time updates (3 providers: NIM, Groq, Cerebras)
 *   - Continuous monitoring with 2-second ping intervals (never stops)
 *   - Rolling averages calculated from ALL successful pings since start
 *   - Best-per-tier highlighting with medals (ğŸ¥‡ğŸ¥ˆğŸ¥‰)
 *   - Interactive navigation with arrow keys directly in the table
 *   - Instant OpenCode OR OpenClaw action on Enter key press
 *   - Startup mode menu (OpenCode CLI vs OpenCode Desktop vs OpenClaw) when no flag is given
 *   - Automatic config detection and model setup for both tools
 *   - JSON config stored in ~/.free-coding-models.json (auto-migrates from old plain-text)
 *   - Multi-provider support via sources.js (NIM, Groq, Cerebras â€” extensible)
 *   - Settings screen (P key) to manage API keys per provider, enable/disable, test keys
 *   - Uptime percentage tracking (successful pings / total pings)
 *   - Sortable columns (R/Y/O/M/L/A/S/N/H/V/U keys)
 *   - Tier filtering via T key (cycles S+â†’Sâ†’A+â†’Aâ†’A-â†’B+â†’Bâ†’Câ†’All)
 *
 *   â†’ Functions:
 *   - `loadConfig` / `saveConfig` / `getApiKey`: Multi-provider JSON config via lib/config.js
 *   - `promptApiKey`: Interactive wizard for first-time NVIDIA API key setup
 *   - `promptModeSelection`: Startup menu to choose OpenCode vs OpenClaw
 *   - `ping`: Perform HTTP request to NIM endpoint with timeout handling
 *   - `renderTable`: Generate ASCII table with colored latency indicators and status emojis
 *   - `getAvg`: Calculate average latency from all successful pings
 *   - `getVerdict`: Determine verdict string based on average latency (Overloaded for 429)
 *   - `getUptime`: Calculate uptime percentage from ping history
 *   - `sortResults`: Sort models by various columns
 *   - `checkNvidiaNimConfig`: Check if NVIDIA NIM provider is configured in OpenCode
 *   - `startOpenCode`: Launch OpenCode CLI with selected model (configures if needed)
 *   - `startOpenCodeDesktop`: Set model in shared config & open OpenCode Desktop app
 *   - `loadOpenClawConfig` / `saveOpenClawConfig`: Manage ~/.openclaw/openclaw.json
 *   - `startOpenClaw`: Set selected model as default in OpenClaw config (remote, no launch)
 *   - `filterByTier`: Filter models by tier letter prefix (S, A, B, C)
 *   - `main`: Orchestrates CLI flow, wizard, ping loops, animation, and output
 *
 *   ğŸ“¦ Dependencies:
 *   - Node.js 18+ (native fetch)
 *   - chalk: Terminal styling and colors
 *   - readline: Interactive input handling
 *   - sources.js: Model definitions from all providers
 *
 *   âš™ï¸ Configuration:
 *   - API keys stored per-provider in ~/.free-coding-models.json (0600 perms)
 *   - Old ~/.free-coding-models plain-text auto-migrated as nvidia key on first run
 *   - Env vars override config: NVIDIA_API_KEY, GROQ_API_KEY, CEREBRAS_API_KEY
 *   - Models loaded from sources.js â€” 53 models across NIM, Groq, Cerebras
 *   - OpenCode config: ~/.config/opencode/opencode.json
 *   - OpenClaw config: ~/.openclaw/openclaw.json
 *   - Ping timeout: 15s per attempt
 *   - Ping interval: 2 seconds (continuous monitoring mode)
 *   - Animation: 12 FPS with braille spinners
 *
 *   ğŸš€ CLI flags:
 *   - (no flag): Show startup menu â†’ choose OpenCode or OpenClaw
 *   - --opencode: OpenCode CLI mode (launch CLI with selected model)
 *   - --opencode-desktop: OpenCode Desktop mode (set model & open Desktop app)
 *   - --openclaw: OpenClaw mode (set selected model as default in OpenClaw)
 *   - --best: Show only top-tier models (A+, S, S+)
 *   - --fiable: Analyze 10s and output the most reliable model
 *   - --tier S/A/B/C: Filter models by tier letter (S=S+/S, A=A+/A/A-, B=B+/B, C=C)
 *
 *   @see {@link https://build.nvidia.com} NVIDIA API key generation
 *   @see {@link https://github.com/opencode-ai/opencode} OpenCode repository
 *   @see {@link https://openclaw.ai} OpenClaw documentation
 */

import chalk from 'chalk'
import { createRequire } from 'module'
import { readFileSync, writeFileSync, existsSync, copyFileSync, mkdirSync } from 'fs'
import { homedir } from 'os'
import { join, dirname } from 'path'
import { MODELS, sources } from '../sources.js'
import { patchOpenClawModelsJson } from '../patch-openclaw-models.js'
import { getAvg, getVerdict, getUptime, sortResults, filterByTier, findBestModel, parseArgs, TIER_ORDER, VERDICT_ORDER, TIER_LETTER_MAP } from '../lib/utils.js'
import { loadConfig, saveConfig, getApiKey, isProviderEnabled } from '../lib/config.js'

const require = createRequire(import.meta.url)
const readline = require('readline')

// â”€â”€â”€ Version check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const pkg = require('../package.json')
const LOCAL_VERSION = pkg.version

async function checkForUpdate() {
  try {
    const res = await fetch('https://registry.npmjs.org/free-coding-models/latest', { signal: AbortSignal.timeout(5000) })
    if (!res.ok) return null
    const data = await res.json()
    if (data.version && data.version !== LOCAL_VERSION) return data.version
  } catch {}
  return null
}

function runUpdate(latestVersion) {
  const { execSync } = require('child_process')
  console.log()
  console.log(chalk.bold.cyan('  â¬† Updating free-coding-models to v' + latestVersion + '...'))
  console.log()
  
  try {
    // ğŸ“– Force install from npm registry (ignore local cache)
    // ğŸ“– Use --prefer-online to ensure we get the latest published version
    execSync(`npm i -g free-coding-models@${latestVersion} --prefer-online`, { stdio: 'inherit' })
    console.log()
    console.log(chalk.green('  âœ… Update complete! Version ' + latestVersion + ' installed.'))
    console.log()
    console.log(chalk.dim('  ğŸ”„ Restarting with new version...'))
    console.log()
    
    // ğŸ“– Relaunch automatically with the same arguments
    const args = process.argv.slice(2)
    execSync(`node bin/free-coding-models.js ${args.join(' ')}`, { stdio: 'inherit' })
    process.exit(0)
  } catch (err) {
    console.log()
    // ğŸ“– Check if error is permission-related (EACCES or EPERM)
    const isPermissionError = err.code === 'EACCES' || err.code === 'EPERM' || 
                             (err.stderr && (err.stderr.includes('EACCES') || err.stderr.includes('permission') || 
                                              err.stderr.includes('EACCES'))) ||
                             (err.message && (err.message.includes('EACCES') || err.message.includes('permission')))
    
    if (isPermissionError) {
      console.log(chalk.yellow('  âš ï¸ Permission denied. Retrying with sudo...'))
      console.log()
      try {
        execSync(`sudo npm i -g free-coding-models@${latestVersion} --prefer-online`, { stdio: 'inherit' })
        console.log()
        console.log(chalk.green('  âœ… Update complete with sudo! Version ' + latestVersion + ' installed.'))
        console.log()
        console.log(chalk.dim('  ğŸ”„ Restarting with new version...'))
        console.log()
        
        // ğŸ“– Relaunch automatically with the same arguments
        const args = process.argv.slice(2)
        execSync(`node bin/free-coding-models.js ${args.join(' ')}`, { stdio: 'inherit' })
        process.exit(0)
      } catch (sudoErr) {
        console.log()
        console.log(chalk.red('  âœ– Update failed even with sudo. Try manually:'))
        console.log(chalk.dim('    sudo npm i -g free-coding-models@' + latestVersion))
        console.log()
      }
    } else {
      console.log(chalk.red('  âœ– Update failed. Try manually: npm i -g free-coding-models@' + latestVersion))
      console.log()
    }
  }
  process.exit(1)
}

// ğŸ“– Config is now managed via lib/config.js (JSON format ~/.free-coding-models.json)
// ğŸ“– loadConfig/saveConfig/getApiKey are imported above

// â”€â”€â”€ First-run wizard â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– Shown when NO provider has a key configured yet.
// ğŸ“– Steps through all 3 providers sequentially â€” each is optional (Enter to skip).
// ğŸ“– At least one key must be entered to proceed. Keys saved to ~/.free-coding-models.json.
// ğŸ“– Returns the nvidia key (or null) for backward-compat with the rest of main().
async function promptApiKey(config) {
  console.log()
  console.log(chalk.bold('  ğŸ”‘ First-time setup â€” API keys'))
  console.log(chalk.dim('  Enter keys for any provider you want to use. Press Enter to skip one.'))
  console.log()

  // ğŸ“– Provider definitions: label, key field, url for getting the key
  const providers = [
    {
      key: 'nvidia',
      label: 'NVIDIA NIM',
      color: chalk.rgb(118, 185, 0),
      url: 'https://build.nvidia.com',
      hint: 'Profile â†’ API Keys â†’ Generate',
      prefix: 'nvapi-',
    },
    {
      key: 'groq',
      label: 'Groq',
      color: chalk.rgb(249, 103, 20),
      url: 'https://console.groq.com/keys',
      hint: 'API Keys â†’ Create API Key',
      prefix: 'gsk_',
    },
    {
      key: 'cerebras',
      label: 'Cerebras',
      color: chalk.rgb(0, 180, 255),
      url: 'https://cloud.cerebras.ai',
      hint: 'API Keys â†’ Create',
      prefix: 'csk_ / cauth_',
    },
    {
      key: 'sambanova',
      label: 'SambaNova',
      color: chalk.rgb(255, 165, 0),
      url: 'https://cloud.sambanova.ai/apis',
      hint: 'API Keys â†’ Create ($5 free trial, 3 months)',
      prefix: 'sn-',
    },
    {
      key: 'openrouter',
      label: 'OpenRouter',
      color: chalk.rgb(120, 80, 255),
      url: 'https://openrouter.ai/settings/keys',
      hint: 'API Keys â†’ Create key (50 free req/day, shared quota)',
      prefix: 'sk-or-',
    },
    {
      key: 'codestral',
      label: 'Mistral Codestral',
      color: chalk.rgb(255, 100, 100),
      url: 'https://codestral.mistral.ai',
      hint: 'API Keys â†’ Create key (30 req/min, 2000/day â€” phone required)',
      prefix: 'csk-',
    },
    {
      key: 'hyperbolic',
      label: 'Hyperbolic',
      color: chalk.rgb(0, 200, 150),
      url: 'https://app.hyperbolic.ai/settings',
      hint: 'Settings â†’ API Keys ($1 free trial)',
      prefix: 'eyJ',
    },
    {
      key: 'scaleway',
      label: 'Scaleway',
      color: chalk.rgb(130, 0, 250),
      url: 'https://console.scaleway.com/iam/api-keys',
      hint: 'IAM â†’ API Keys (1M free tokens)',
      prefix: 'scw-',
    },
    {
      key: 'googleai',
      label: 'Google AI Studio',
      color: chalk.rgb(66, 133, 244),
      url: 'https://aistudio.google.com/apikey',
      hint: 'Get API key (free Gemma models, 14.4K req/day)',
      prefix: 'AIza',
    },
  ]

  const rl = readline.createInterface({ input: process.stdin, output: process.stdout })

  // ğŸ“– Ask a single question â€” returns trimmed string or '' for skip
  const ask = (question) => new Promise((resolve) => {
    rl.question(question, (answer) => resolve(answer.trim()))
  })

  for (const p of providers) {
    console.log(`  ${p.color('â—')} ${chalk.bold(p.label)}`)
    console.log(chalk.dim(`    Free key at: `) + chalk.cyanBright(p.url))
    console.log(chalk.dim(`    ${p.hint}`))
    const answer = await ask(chalk.dim(`  Enter key (or Enter to skip): `))
    console.log()
    if (answer) {
      config.apiKeys[p.key] = answer
    }
  }

  rl.close()

  // ğŸ“– Check at least one key was entered
  const anyKey = Object.values(config.apiKeys).some(v => v)
  if (!anyKey) {
    return null
  }

  saveConfig(config)
  const savedCount = Object.values(config.apiKeys).filter(v => v).length
  console.log(chalk.green(`  âœ… ${savedCount} key(s) saved to ~/.free-coding-models.json`))
  console.log(chalk.dim('  You can add or change keys anytime with the ') + chalk.yellow('P') + chalk.dim(' key in the TUI.'))
  console.log()

  // ğŸ“– Return nvidia key for backward-compat (main() checks it exists before continuing)
  return config.apiKeys.nvidia || Object.values(config.apiKeys).find(v => v) || null
}

// â”€â”€â”€ Update notification menu â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– Shown ONLY when a new version is available, to prompt user to update
// ğŸ“– Centered, clean presentation that doesn't block normal usage
// ğŸ“– Returns 'update', 'changelogs', or null to continue without update
async function promptUpdateNotification(latestVersion) {
  if (!latestVersion) return null

  return new Promise((resolve) => {
    let selected = 0
    const options = [
      {
        label: 'Update now',
        icon: 'â¬†',
        description: `Update free-coding-models to v${latestVersion}`,
      },
      {
        label: 'Read Changelogs',
        icon: 'ğŸ“‹',
        description: 'Open GitHub changelog',
      },
      {
        label: 'Continue without update',
        icon: 'â–¶',
        description: 'Use current version',
      },
    ]

    // ğŸ“– Centered render function
    const render = () => {
      process.stdout.write('\x1b[2J\x1b[H') // clear screen + cursor home
      
      // ğŸ“– Calculate centering
      const terminalWidth = process.stdout.columns || 80
      const maxWidth = Math.min(terminalWidth - 4, 70)
      const centerPad = ' '.repeat(Math.max(0, Math.floor((terminalWidth - maxWidth) / 2)))
      
      console.log()
      console.log(centerPad + chalk.bold.red('  âš  UPDATE AVAILABLE'))
      console.log(centerPad + chalk.red(`  Version ${latestVersion} is ready to install`))
      console.log()
      console.log(centerPad + chalk.bold('  âš¡ Free Coding Models') + chalk.dim(` v${LOCAL_VERSION}`))
      console.log()
      
      for (let i = 0; i < options.length; i++) {
        const isSelected = i === selected
        const bullet = isSelected ? chalk.bold.cyan('  â¯ ') : chalk.dim('    ')
        const label = isSelected
          ? chalk.bold.white(options[i].icon + ' ' + options[i].label)
          : chalk.dim(options[i].icon + ' ' + options[i].label)
        
        console.log(centerPad + bullet + label)
        console.log(centerPad + chalk.dim('       ' + options[i].description))
        console.log()
      }
      
      console.log(centerPad + chalk.dim('  â†‘â†“ Navigate  â€¢  Enter Select  â€¢  Ctrl+C Continue'))
      console.log()
    }

    render()

    readline.emitKeypressEvents(process.stdin)
    if (process.stdin.isTTY) process.stdin.setRawMode(true)

    const onKey = (_str, key) => {
      if (!key) return
      if (key.ctrl && key.name === 'c') {
        if (process.stdin.isTTY) process.stdin.setRawMode(false)
        process.stdin.removeListener('keypress', onKey)
        resolve(null) // Continue without update
        return
      }
      if (key.name === 'up' && selected > 0) {
        selected--
        render()
      } else if (key.name === 'down' && selected < options.length - 1) {
        selected++
        render()
      } else if (key.name === 'return') {
        if (process.stdin.isTTY) process.stdin.setRawMode(false)
        process.stdin.removeListener('keypress', onKey)
        process.stdin.pause()
        
        if (selected === 0) resolve('update')
        else if (selected === 1) resolve('changelogs')
        else resolve(null) // Continue without update
      }
    }

    process.stdin.on('keypress', onKey)
  })
}

// â”€â”€â”€ Alternate screen control â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– \x1b[?1049h = enter alt screen  \x1b[?1049l = leave alt screen
// ğŸ“– \x1b[?25l   = hide cursor       \x1b[?25h   = show cursor
// ğŸ“– \x1b[H      = cursor to top
// ğŸ“– NOTE: We avoid \x1b[2J (clear screen) because Ghostty scrolls cleared
// ğŸ“– content into the scrollback on the alt screen, pushing the header off-screen.
// ğŸ“– Instead we overwrite in place: cursor home, then \x1b[K (erase to EOL) per line.
// ğŸ“– \x1b[?7l disables auto-wrap so wide rows clip at the right edge instead of
// ğŸ“– wrapping to the next line (which would double the row height and overflow).
const ALT_ENTER  = '\x1b[?1049h\x1b[?25l\x1b[?7l'
const ALT_LEAVE  = '\x1b[?7h\x1b[?1049l\x1b[?25h'
const ALT_HOME   = '\x1b[H'

// â”€â”€â”€ API Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– Models are now loaded from sources.js to support multiple providers
// ğŸ“– This allows easy addition of new model sources beyond NVIDIA NIM

const PING_TIMEOUT  = 15_000   // ğŸ“– 15s per attempt before abort - slow models get more time
const PING_INTERVAL = 2_000    // ğŸ“– Ping all models every 2 seconds in continuous mode

const FPS          = 12
const COL_MODEL    = 22
// ğŸ“– COL_MS = dashes in hline per ping column = visual width including 2 padding spaces
// ğŸ“– Max value: 12001ms = 7 chars. padStart(COL_MS-2) fits content, +2 spaces = COL_MS dashes
// ğŸ“– COL_MS 11 â†’ content padded to 9 â†’ handles up to "12001ms" (7 chars) with room
const COL_MS       = 11

// â”€â”€â”€ Styling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– Tier colors: green gradient (best) â†’ yellow â†’ orange â†’ red (worst)
// ğŸ“– Uses chalk.rgb() for fine-grained color control across 8 tier levels
const TIER_COLOR = {
  'S+': t => chalk.bold.rgb(0,   255,  80)(t),   // ğŸŸ¢ bright neon green  â€” elite
  'S':  t => chalk.bold.rgb(80,  220,   0)(t),   // ğŸŸ¢ green              â€” excellent
  'A+': t => chalk.bold.rgb(170, 210,   0)(t),   // ğŸŸ¡ yellow-green       â€” great
  'A':  t => chalk.bold.rgb(240, 190,   0)(t),   // ğŸŸ¡ yellow             â€” good
  'A-': t => chalk.bold.rgb(255, 130,   0)(t),   // ğŸŸ  amber              â€” decent
  'B+': t => chalk.bold.rgb(255,  70,   0)(t),   // ğŸŸ  orange-red         â€” average
  'B':  t => chalk.bold.rgb(210,  20,   0)(t),   // ğŸ”´ red                â€” below avg
  'C':  t => chalk.bold.rgb(140,   0,   0)(t),   // ğŸ”´ dark red           â€” lightweight
}

// ğŸ“– COL_MS - 2 = visual content width (the 2 padding spaces are handled by â”‚ x â”‚ template)
const CELL_W = COL_MS - 2  // 9 chars of content per ms cell

const msCell = (ms) => {
  if (ms === null) return chalk.dim('â€”'.padStart(CELL_W))
  const str = String(ms).padStart(CELL_W)
  if (ms === 'TIMEOUT') return chalk.red(str)
  if (ms < 500)  return chalk.greenBright(str)
  if (ms < 1500) return chalk.yellow(str)
  return chalk.red(str)
}

const FRAMES = ['â ‹','â ™','â ¹','â ¸','â ¼','â ´','â ¦','â §','â ‡','â ']
// ğŸ“– Spinner cell: braille (1-wide) + padding to fill CELL_W visual chars
const spinCell = (f, o = 0) => chalk.dim.yellow(FRAMES[(f + o) % FRAMES.length].padEnd(CELL_W))

// â”€â”€â”€ Table renderer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// ğŸ“– Core logic functions (getAvg, getVerdict, getUptime, sortResults, etc.)
// ğŸ“– are imported from lib/utils.js for testability

// â”€â”€â”€ Viewport calculation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– Computes the visible slice of model rows that fits in the terminal.
// ğŸ“– Fixed lines: 5 header + 5 footer = 10 lines always consumed.
// ğŸ“– Header: empty, title, empty, column headers, separator (5)
// ğŸ“– Footer: empty, hints, empty, credit, empty (5)
// ğŸ“– When scroll indicators are needed, they each consume 1 line from the model budget.
function calculateViewport(terminalRows, scrollOffset, totalModels) {
  if (terminalRows <= 0) return { startIdx: 0, endIdx: totalModels, hasAbove: false, hasBelow: false }
  let maxSlots = terminalRows - 10  // 5 header + 5 footer
  if (maxSlots < 1) maxSlots = 1
  if (totalModels <= maxSlots) return { startIdx: 0, endIdx: totalModels, hasAbove: false, hasBelow: false }

  const hasAbove = scrollOffset > 0
  const hasBelow = scrollOffset + maxSlots - (hasAbove ? 1 : 0) < totalModels
  // Recalculate with indicator lines accounted for
  const modelSlots = maxSlots - (hasAbove ? 1 : 0) - (hasBelow ? 1 : 0)
  const endIdx = Math.min(scrollOffset + modelSlots, totalModels)
  return { startIdx: scrollOffset, endIdx, hasAbove, hasBelow }
}

// ğŸ“– renderTable: mode param controls footer hint text (opencode vs openclaw)
function renderTable(results, pendingPings, frame, cursor = null, sortColumn = 'avg', sortDirection = 'asc', pingInterval = PING_INTERVAL, lastPingTime = Date.now(), mode = 'opencode', tierFilterMode = 0, scrollOffset = 0, terminalRows = 0, originFilterMode = 0) {
  // ğŸ“– Filter out hidden models for display
  const visibleResults = results.filter(r => !r.hidden)

  const up      = visibleResults.filter(r => r.status === 'up').length
  const down    = visibleResults.filter(r => r.status === 'down').length
  const timeout = visibleResults.filter(r => r.status === 'timeout').length
  const pending = visibleResults.filter(r => r.status === 'pending').length

  // ğŸ“– Calculate seconds until next ping
  const timeSinceLastPing = Date.now() - lastPingTime
  const timeUntilNextPing = Math.max(0, pingInterval - timeSinceLastPing)
  const secondsUntilNext = Math.ceil(timeUntilNextPing / 1000)

  const phase = pending > 0
    ? chalk.dim(`discovering â€” ${pending} remainingâ€¦`)
    : pendingPings > 0
      ? chalk.dim(`pinging â€” ${pendingPings} in flightâ€¦`)
      : chalk.dim(`next ping ${secondsUntilNext}s`)

  // ğŸ“– Mode badge shown in header so user knows what Enter will do
  // ğŸ“– Now includes key hint for mode toggle
  let modeBadge
  if (mode === 'openclaw') {
    modeBadge = chalk.bold.rgb(255, 100, 50)(' [ğŸ¦ OpenClaw]')
  } else if (mode === 'opencode-desktop') {
    modeBadge = chalk.bold.rgb(0, 200, 255)(' [ğŸ–¥ Desktop]')
  } else {
    modeBadge = chalk.bold.rgb(0, 200, 255)(' [ğŸ’» CLI]')
  }
  
  // ğŸ“– Add mode toggle hint
  const modeHint = chalk.dim.yellow(' (Z to toggle)')

  // ğŸ“– Tier filter badge shown when filtering is active (shows exact tier name)
  const TIER_CYCLE_NAMES = [null, 'S+', 'S', 'A+', 'A', 'A-', 'B+', 'B', 'C']
  let tierBadge = ''
  if (tierFilterMode > 0) {
    tierBadge = chalk.bold.rgb(255, 200, 0)(` [${TIER_CYCLE_NAMES[tierFilterMode]}]`)
  }

  // ğŸ“– Origin filter badge â€” shown when filtering by provider is active
  let originBadge = ''
  if (originFilterMode > 0) {
    const originKeys = [null, ...Object.keys(sources)]
    const activeOriginKey = originKeys[originFilterMode]
    const activeOriginName = activeOriginKey ? sources[activeOriginKey]?.name ?? activeOriginKey : null
    if (activeOriginName) {
      originBadge = chalk.bold.rgb(100, 200, 255)(` [${activeOriginName}]`)
    }
  }

  // ğŸ“– Column widths (generous spacing with margins)
  const W_RANK = 6
  const W_TIER = 6
  const W_CTX = 6
  const W_SOURCE = 14
  const W_MODEL = 26
  const W_SWE = 9
  const W_PING = 14
  const W_AVG = 11
  const W_STATUS = 18
  const W_VERDICT = 14
  const W_UPTIME = 6

  // ğŸ“– Sort models using the shared helper
  const sorted = sortResults(visibleResults, sortColumn, sortDirection)

  const lines = [
    '',
    `  ${chalk.bold('âš¡ Free Coding Models')} ${chalk.dim('v' + LOCAL_VERSION)}${modeBadge}${modeHint}${tierBadge}${originBadge}   ` +
      chalk.greenBright(`âœ… ${up}`) + chalk.dim(' up  ') +
      chalk.yellow(`â³ ${timeout}`) + chalk.dim(' timeout  ') +
      chalk.red(`âŒ ${down}`) + chalk.dim(' down  ') +
      phase,
    '',
  ]

  // ğŸ“– Header row with sorting indicators
  // ğŸ“– NOTE: padEnd on chalk strings counts ANSI codes, breaking alignment
  // ğŸ“– Solution: build plain text first, then colorize
  const dir = sortDirection === 'asc' ? 'â†‘' : 'â†“'

  const rankH    = 'Rank'
  const tierH    = 'Tier'
  const originH  = 'Origin'
  const modelH   = 'Model'
  const sweH     = sortColumn === 'swe' ? dir + ' SWE%' : 'SWE%'
  const ctxH     = sortColumn === 'ctx' ? dir + ' CTX' : 'CTX'
  const pingH    = sortColumn === 'ping' ? dir + ' Latest Ping' : 'Latest Ping'
  const avgH     = sortColumn === 'avg' ? dir + ' Avg Ping' : 'Avg Ping'
  const healthH  = sortColumn === 'condition' ? dir + ' Health' : 'Health'
  const verdictH = sortColumn === 'verdict' ? dir + ' Verdict' : 'Verdict'
  const uptimeH  = sortColumn === 'uptime' ? dir + ' Up%' : 'Up%'

  // ğŸ“– Helper to colorize first letter for keyboard shortcuts
  // ğŸ“– IMPORTANT: Pad PLAIN TEXT first, then apply colors to avoid alignment issues
  const colorFirst = (text, width, colorFn = chalk.yellow) => {
    const first = text[0]
    const rest = text.slice(1)
    const plainText = first + rest
    const padding = ' '.repeat(Math.max(0, width - plainText.length))
    return colorFn(first) + chalk.dim(rest + padding)
  }

  // ğŸ“– Now colorize after padding is calculated on plain text
  const rankH_c    = colorFirst(rankH, W_RANK)
  const tierH_c    = colorFirst('Tier', W_TIER)
  const originLabel = 'Origin(N)'
  const originH_c  = sortColumn === 'origin'
    ? chalk.bold.cyan(originLabel.padEnd(W_SOURCE))
    : (originFilterMode > 0 ? chalk.bold.rgb(100, 200, 255)(originLabel.padEnd(W_SOURCE)) : colorFirst(originLabel, W_SOURCE))
  const modelH_c   = colorFirst(modelH, W_MODEL)
  const sweH_c     = sortColumn === 'swe' ? chalk.bold.cyan(sweH.padEnd(W_SWE)) : colorFirst(sweH, W_SWE)
  const ctxH_c     = sortColumn === 'ctx' ? chalk.bold.cyan(ctxH.padEnd(W_CTX)) : colorFirst(ctxH, W_CTX)
  const pingH_c    = sortColumn === 'ping' ? chalk.bold.cyan(pingH.padEnd(W_PING)) : colorFirst('Latest Ping', W_PING)
  const avgH_c     = sortColumn === 'avg' ? chalk.bold.cyan(avgH.padEnd(W_AVG)) : colorFirst('Avg Ping', W_AVG)
  const healthH_c  = sortColumn === 'condition' ? chalk.bold.cyan(healthH.padEnd(W_STATUS)) : colorFirst('Health', W_STATUS)
  const verdictH_c = sortColumn === 'verdict' ? chalk.bold.cyan(verdictH.padEnd(W_VERDICT)) : colorFirst(verdictH, W_VERDICT)
  const uptimeH_c  = sortColumn === 'uptime' ? chalk.bold.cyan(uptimeH.padStart(W_UPTIME)) : colorFirst(uptimeH, W_UPTIME, chalk.green)

  // ğŸ“– Header with proper spacing (column order: Rank, Tier, SWE%, CTX, Model, Origin, Latest Ping, Avg Ping, Health, Verdict, Up%)
  lines.push('  ' + rankH_c + '  ' + tierH_c + '  ' + sweH_c + '  ' + ctxH_c + '  ' + modelH_c + '  ' + originH_c + '  ' + pingH_c + '  ' + avgH_c + '  ' + healthH_c + '  ' + verdictH_c + '  ' + uptimeH_c)

  // ğŸ“– Separator line
  lines.push(
    '  ' +
    chalk.dim('â”€'.repeat(W_RANK)) + '  ' +
    chalk.dim('â”€'.repeat(W_TIER)) + '  ' +
    chalk.dim('â”€'.repeat(W_SWE)) + '  ' +
    chalk.dim('â”€'.repeat(W_CTX)) + '  ' +
    'â”€'.repeat(W_MODEL) + '  ' +
    'â”€'.repeat(W_SOURCE) + '  ' +
    chalk.dim('â”€'.repeat(W_PING)) + '  ' +
    chalk.dim('â”€'.repeat(W_AVG)) + '  ' +
    chalk.dim('â”€'.repeat(W_STATUS)) + '  ' +
    chalk.dim('â”€'.repeat(W_VERDICT)) + '  ' +
    chalk.dim('â”€'.repeat(W_UPTIME))
  )

  // ğŸ“– Viewport clipping: only render models that fit on screen
  const vp = calculateViewport(terminalRows, scrollOffset, sorted.length)

  if (vp.hasAbove) {
    lines.push(chalk.dim(`  ... ${vp.startIdx} more above ...`))
  }

  for (let i = vp.startIdx; i < vp.endIdx; i++) {
    const r = sorted[i]
    const tierFn = TIER_COLOR[r.tier] ?? (t => chalk.white(t))

    const isCursor = cursor !== null && i === cursor

    // ğŸ“– Left-aligned columns - pad plain text first, then colorize
    const num = chalk.dim(String(r.idx).padEnd(W_RANK))
    const tier = tierFn(r.tier.padEnd(W_TIER))
    // ğŸ“– Show provider name from sources map (NIM / Groq / Cerebras)
    const providerName = sources[r.providerKey]?.name ?? r.providerKey ?? 'NIM'
    const source = chalk.green(providerName.padEnd(W_SOURCE))
    const name = r.label.slice(0, W_MODEL).padEnd(W_MODEL)
    const sweScore = r.sweScore ?? 'â€”'
    const sweCell = sweScore !== 'â€”' && parseFloat(sweScore) >= 50 
      ? chalk.greenBright(sweScore.padEnd(W_SWE))
      : sweScore !== 'â€”' && parseFloat(sweScore) >= 30
      ? chalk.yellow(sweScore.padEnd(W_SWE))
      : chalk.dim(sweScore.padEnd(W_SWE))
    
    // ğŸ“– Context window column - colorized by size (larger = better)
    const ctxRaw = r.ctx ?? 'â€”'
    const ctxCell = ctxRaw !== 'â€”' && (ctxRaw.includes('128k') || ctxRaw.includes('200k') || ctxRaw.includes('1m'))
      ? chalk.greenBright(ctxRaw.padEnd(W_CTX))
      : ctxRaw !== 'â€”' && (ctxRaw.includes('32k') || ctxRaw.includes('64k'))
      ? chalk.cyan(ctxRaw.padEnd(W_CTX))
      : chalk.dim(ctxRaw.padEnd(W_CTX))

    // ğŸ“– Latest ping - pings are objects: { ms, code }
    // ğŸ“– Show response time for 200 (success) and 401 (no-auth but server is reachable)
    const latestPing = r.pings.length > 0 ? r.pings[r.pings.length - 1] : null
    let pingCell
    if (!latestPing) {
      pingCell = chalk.dim('â€”'.padEnd(W_PING))
    } else if (latestPing.code === '200') {
      // ğŸ“– Success - show response time
      const str = String(latestPing.ms).padEnd(W_PING)
      pingCell = latestPing.ms < 500 ? chalk.greenBright(str) : latestPing.ms < 1500 ? chalk.yellow(str) : chalk.red(str)
    } else if (latestPing.code === '401') {
      // ğŸ“– 401 = no API key but server IS reachable â€” still show latency in dim
      pingCell = chalk.dim(String(latestPing.ms).padEnd(W_PING))
    } else {
      // ğŸ“– Error or timeout - show "â€”" (error code is already in Status column)
      pingCell = chalk.dim('â€”'.padEnd(W_PING))
    }

    // ğŸ“– Avg ping (just number, no "ms")
    const avg = getAvg(r)
    let avgCell
    if (avg !== Infinity) {
      const str = String(avg).padEnd(W_AVG)
      avgCell = avg < 500 ? chalk.greenBright(str) : avg < 1500 ? chalk.yellow(str) : chalk.red(str)
    } else {
      avgCell = chalk.dim('â€”'.padEnd(W_AVG))
    }

    // ğŸ“– Status column - build plain text with emoji, pad, then colorize
    // ğŸ“– Different emojis for different error codes
    let statusText, statusColor
    if (r.status === 'noauth') {
      // ğŸ“– Server responded but needs an API key â€” shown dimly since it IS reachable
      statusText = `ğŸ”‘ NO KEY`
      statusColor = (s) => chalk.dim(s)
    } else if (r.status === 'pending') {
      statusText = `${FRAMES[frame % FRAMES.length]} wait`
      statusColor = (s) => chalk.dim.yellow(s)
    } else if (r.status === 'up') {
      statusText = `âœ… UP`
      statusColor = (s) => s
    } else if (r.status === 'timeout') {
      statusText = `â³ TIMEOUT`
      statusColor = (s) => chalk.yellow(s)
    } else if (r.status === 'down') {
      const code = r.httpCode ?? 'ERR'
      // ğŸ“– Different emojis for different error codes
      const errorEmojis = {
        '429': 'ğŸ”¥',  // Rate limited / overloaded
        '404': 'ğŸš«',  // Not found
        '500': 'ğŸ’¥',  // Internal server error
        '502': 'ğŸ”Œ',  // Bad gateway
        '503': 'ğŸ”’',  // Service unavailable
        '504': 'â°',  // Gateway timeout
      }
      const emoji = errorEmojis[code] || 'âŒ'
      statusText = `${emoji} ${code}`
      statusColor = (s) => chalk.red(s)
    } else {
      statusText = '?'
      statusColor = (s) => chalk.dim(s)
    }
    const status = statusColor(statusText.padEnd(W_STATUS))

    // ğŸ“– Verdict column - build plain text with emoji, pad, then colorize
    const wasUpBefore = r.pings.length > 0 && r.pings.some(p => p.code === '200')
    let verdictText, verdictColor
    if (r.httpCode === '429') {
      verdictText = 'ğŸ”¥ Overloaded'
      verdictColor = (s) => chalk.yellow.bold(s)
    } else if ((r.status === 'timeout' || r.status === 'down') && wasUpBefore) {
      verdictText = 'âš ï¸ Unstable'
      verdictColor = (s) => chalk.magenta(s)
    } else if (r.status === 'timeout' || r.status === 'down') {
      verdictText = 'ğŸ‘» Not Active'
      verdictColor = (s) => chalk.dim(s)
    } else if (avg === Infinity) {
      verdictText = 'â³ Pending'
      verdictColor = (s) => chalk.dim(s)
    } else if (avg < 400) {
      verdictText = 'ğŸš€ Perfect'
      verdictColor = (s) => chalk.greenBright(s)
    } else if (avg < 1000) {
      verdictText = 'âœ… Normal'
      verdictColor = (s) => chalk.cyan(s)
    } else if (avg < 3000) {
      verdictText = 'ğŸ¢ Slow'
      verdictColor = (s) => chalk.yellow(s)
    } else if (avg < 5000) {
      verdictText = 'ğŸŒ Very Slow'
      verdictColor = (s) => chalk.red(s)
    } else {
      verdictText = 'ğŸ’€ Unusable'
      verdictColor = (s) => chalk.red.bold(s)
    }
    const speedCell = verdictColor(verdictText.padEnd(W_VERDICT))

    // ğŸ“– Uptime column - percentage of successful pings
    const uptimePercent = getUptime(r)
    const uptimeStr = uptimePercent + '%'
    let uptimeCell
    if (uptimePercent >= 90) {
      uptimeCell = chalk.greenBright(uptimeStr.padStart(W_UPTIME))
    } else if (uptimePercent >= 70) {
      uptimeCell = chalk.yellow(uptimeStr.padStart(W_UPTIME))
    } else if (uptimePercent >= 50) {
      uptimeCell = chalk.rgb(255, 165, 0)(uptimeStr.padStart(W_UPTIME)) // orange
    } else {
      uptimeCell = chalk.red(uptimeStr.padStart(W_UPTIME))
    }

    // ğŸ“– Build row with double space between columns (order: Rank, Tier, SWE%, CTX, Model, Origin, Latest Ping, Avg Ping, Health, Verdict, Up%)
    const row = '  ' + num + '  ' + tier + '  ' + sweCell + '  ' + ctxCell + '  ' + name + '  ' + source + '  ' + pingCell + '  ' + avgCell + '  ' + status + '  ' + speedCell + '  ' + uptimeCell

    if (isCursor) {
      lines.push(chalk.bgRgb(139, 0, 139)(row))
    } else {
      lines.push(row)
    }
  }

  if (vp.hasBelow) {
    lines.push(chalk.dim(`  ... ${sorted.length - vp.endIdx} more below ...`))
  }

  lines.push('')
  const intervalSec = Math.round(pingInterval / 1000)

  // ğŸ“– Footer hints adapt based on active mode
  const actionHint = mode === 'openclaw'
    ? chalk.rgb(255, 100, 50)('Enterâ†’SetOpenClaw')
    : mode === 'opencode-desktop'
      ? chalk.rgb(0, 200, 255)('Enterâ†’OpenDesktop')
      : chalk.rgb(0, 200, 255)('Enterâ†’OpenCode')
  lines.push(chalk.dim(`  â†‘â†“ Navigate  â€¢  `) + actionHint + chalk.dim(`  â€¢  R/Y/O/M/L/A/S/C/H/V/U Sort  â€¢  T Tier  â€¢  N Origin  â€¢  Wâ†“/Xâ†‘ (${intervalSec}s)  â€¢  Z Mode  â€¢  `) + chalk.yellow('P') + chalk.dim(` Settings  â€¢  `) + chalk.yellow('K') + chalk.dim(` Help  â€¢  Ctrl+C Exit`))
  lines.push('')
  lines.push(chalk.dim('  Made with ') + 'ğŸ’– & â˜•' + chalk.dim(' by ') + '\x1b]8;;https://github.com/vava-nessa\x1b\\vava-nessa\x1b]8;;\x1b\\' + chalk.dim('  â€¢  ') + 'â­ ' + '\x1b]8;;https://github.com/vava-nessa/free-coding-models\x1b\\Star on GitHub\x1b]8;;\x1b\\')
  // ğŸ“– Discord invite + BETA warning â€” always visible at the bottom of the TUI
  lines.push('  ğŸ’¬ ' + chalk.cyanBright('\x1b]8;;https://discord.gg/5MbTnDC3Md\x1b\\Join our Discord\x1b]8;;\x1b\\') + chalk.dim('  â€¢  ') + chalk.yellow('âš  BETA TUI') + chalk.dim(' â€” might crash or have problems'))
  lines.push('')
  // ğŸ“– Append \x1b[K (erase to EOL) to each line so leftover chars from previous
  // ğŸ“– frames are cleared. Then pad with blank cleared lines to fill the terminal,
  // ğŸ“– preventing stale content from lingering at the bottom after resize.
  const EL = '\x1b[K'
  const cleared = lines.map(l => l + EL)
  const remaining = terminalRows > 0 ? Math.max(0, terminalRows - cleared.length) : 0
  for (let i = 0; i < remaining; i++) cleared.push(EL)
  return cleared.join('\n')
}

// â”€â”€â”€ HTTP ping â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

// ğŸ“– ping: Send a single chat completion request to measure model availability and latency.
// ğŸ“– url param is the provider's endpoint URL â€” differs per provider (NIM, Groq, Cerebras).
// ğŸ“– apiKey can be null â€” in that case no Authorization header is sent.
// ğŸ“– A 401 response still tells us the server is UP and gives us real latency.
async function ping(apiKey, modelId, url) {
  const ctrl  = new AbortController()
  const timer = setTimeout(() => ctrl.abort(), PING_TIMEOUT)
  const t0    = performance.now()
  try {
    // ğŸ“– Only attach Authorization header when a key is available
    const headers = { 'Content-Type': 'application/json' }
    if (apiKey) headers['Authorization'] = `Bearer ${apiKey}`
    const resp = await fetch(url, {
      method: 'POST', signal: ctrl.signal,
      headers,
      body: JSON.stringify({ model: modelId, messages: [{ role: 'user', content: 'hi' }], max_tokens: 1 }),
    })
    return { code: String(resp.status), ms: Math.round(performance.now() - t0) }
  } catch (err) {
    const isTimeout = err.name === 'AbortError'
    return {
      code: isTimeout ? '000' : 'ERR',
      ms: isTimeout ? 'TIMEOUT' : Math.round(performance.now() - t0)
    }
  } finally {
    clearTimeout(timer)
  }
}

// â”€â”€â”€ OpenCode integration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– Platform-specific config path
const isWindows = process.platform === 'win32'
const isMac = process.platform === 'darwin'
const isLinux = process.platform === 'linux'

// â”€â”€â”€ OpenCode model ID mapping â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– Source model IDs -> OpenCode built-in model IDs (only where they differ)
// ğŸ“– Groq's API aliases short names to full names, but OpenCode does exact ID matching
// ğŸ“– against its built-in model list. Unmapped models pass through as-is.
const OPENCODE_MODEL_MAP = {
  groq: {
    'moonshotai/kimi-k2-instruct': 'moonshotai/kimi-k2-instruct-0905',
    'meta-llama/llama-4-scout-17b-16e-preview': 'meta-llama/llama-4-scout-17b-16e-instruct',
    'meta-llama/llama-4-maverick-17b-128e-preview': 'meta-llama/llama-4-maverick-17b-128e-instruct',
  }
}

function getOpenCodeModelId(providerKey, modelId) {
  return OPENCODE_MODEL_MAP[providerKey]?.[modelId] || modelId
}

// ğŸ“– Env var names per provider -- used for passing resolved keys to child processes
const ENV_VAR_NAMES = {
  nvidia:     'NVIDIA_API_KEY',
  groq:       'GROQ_API_KEY',
  cerebras:   'CEREBRAS_API_KEY',
  sambanova:  'SAMBANOVA_API_KEY',
  openrouter: 'OPENROUTER_API_KEY',
  codestral:  'CODESTRAL_API_KEY',
  hyperbolic: 'HYPERBOLIC_API_KEY',
  scaleway:   'SCALEWAY_API_KEY',
  googleai:   'GOOGLE_API_KEY',
}

// ğŸ“– OpenCode config location varies by platform
// ğŸ“– Windows: %APPDATA%\opencode\opencode.json (or sometimes ~/.config/opencode)
// ğŸ“– macOS/Linux: ~/.config/opencode/opencode.json
const OPENCODE_CONFIG = isWindows 
  ? join(homedir(), 'AppData', 'Roaming', 'opencode', 'opencode.json')
  : join(homedir(), '.config', 'opencode', 'opencode.json')

// ğŸ“– Fallback to .config on Windows if AppData doesn't exist
const OPENCODE_CONFIG_FALLBACK = join(homedir(), '.config', 'opencode', 'opencode.json')

function getOpenCodeConfigPath() {
  if (existsSync(OPENCODE_CONFIG)) return OPENCODE_CONFIG
  if (isWindows && existsSync(OPENCODE_CONFIG_FALLBACK)) return OPENCODE_CONFIG_FALLBACK
  return OPENCODE_CONFIG
}

function loadOpenCodeConfig() {
  const configPath = getOpenCodeConfigPath()
  if (!existsSync(configPath)) return { provider: {} }
  try {
    return JSON.parse(readFileSync(configPath, 'utf8'))
  } catch {
    return { provider: {} }
  }
}

function saveOpenCodeConfig(config) {
  const configPath = getOpenCodeConfigPath()
  const dir = dirname(configPath)
  if (!existsSync(dir)) {
    mkdirSync(dir, { recursive: true })
  }
  writeFileSync(configPath, JSON.stringify(config, null, 2))
}

// â”€â”€â”€ Check NVIDIA NIM in OpenCode config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– Checks if NVIDIA NIM provider is configured in OpenCode config file
// ğŸ“– OpenCode uses 'provider' (singular) not 'providers' (plural)
// ğŸ“– Returns true if found, false otherwise
function checkNvidiaNimConfig() {
  const config = loadOpenCodeConfig()
  if (!config.provider) return false
  // ğŸ“– Check for nvidia/nim provider by key name or display name (case-insensitive)
  const providerKeys = Object.keys(config.provider)
  return providerKeys.some(key =>
    key === 'nvidia' || key === 'nim' ||
    config.provider[key]?.name?.toLowerCase().includes('nvidia') ||
    config.provider[key]?.name?.toLowerCase().includes('nim')
  )
}

// â”€â”€â”€ Shared OpenCode spawn helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– Resolves the actual API key from config/env and passes it as an env var
// ğŸ“– to the child process so OpenCode's {env:GROQ_API_KEY} references work
// ğŸ“– even when the key is only in ~/.free-coding-models.json (not in shell env).
async function spawnOpenCode(args, providerKey, fcmConfig) {
  const envVarName = ENV_VAR_NAMES[providerKey]
  const resolvedKey = getApiKey(fcmConfig, providerKey)
  const childEnv = { ...process.env }
  if (envVarName && resolvedKey) childEnv[envVarName] = resolvedKey

  const { spawn } = await import('child_process')
  const child = spawn('opencode', args, {
    stdio: 'inherit',
    shell: true,
    detached: false,
    env: childEnv
  })

  return new Promise((resolve, reject) => {
    child.on('exit', resolve)
    child.on('error', (err) => {
      if (err.code === 'ENOENT') {
        console.error(chalk.red('\n  X Could not find "opencode" -- is it installed and in your PATH?'))
        console.error(chalk.dim('    Install: npm i -g opencode   or see https://opencode.ai'))
        resolve(1)
      } else {
        reject(err)
      }
    })
  })
}

// â”€â”€â”€ Start OpenCode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– Launches OpenCode with the selected model.
// ğŸ“– Handles all 3 providers: nvidia (needs custom provider config), groq & cerebras (built-in in OpenCode).
// ğŸ“– For nvidia: checks if NIM is configured, sets provider.models entry, spawns with nvidia/model-id.
// ğŸ“– For groq/cerebras: OpenCode has built-in support -- just sets model in config and spawns.
// ğŸ“– Model format: { modelId, label, tier, providerKey }
// ğŸ“– fcmConfig: the free-coding-models config (for resolving API keys)
async function startOpenCode(model, fcmConfig) {
  const providerKey = model.providerKey ?? 'nvidia'
  // ğŸ“– Map model ID to OpenCode's built-in ID if it differs from our source ID
  const ocModelId = getOpenCodeModelId(providerKey, model.modelId)
  const modelRef = `${providerKey}/${ocModelId}`

  if (providerKey === 'nvidia') {
    // ğŸ“– NVIDIA NIM needs a custom provider block in OpenCode config (not built-in)
    const hasNim = checkNvidiaNimConfig()

    if (hasNim) {
      console.log(chalk.green(`  ğŸš€ Setting ${chalk.bold(model.label)} as defaultâ€¦`))
      console.log(chalk.dim(`  Model: ${modelRef}`))
      console.log()

      const config = loadOpenCodeConfig()
      const backupPath = `${getOpenCodeConfigPath()}.backup-${Date.now()}`

      if (existsSync(getOpenCodeConfigPath())) {
        copyFileSync(getOpenCodeConfigPath(), backupPath)
        console.log(chalk.dim(`  ğŸ’¾ Backup: ${backupPath}`))
      }

      config.model = modelRef

      // ğŸ“– Register the model in the nvidia provider's models section
      if (config.provider?.nvidia) {
        if (!config.provider.nvidia.models) config.provider.nvidia.models = {}
        config.provider.nvidia.models[ocModelId] = { name: model.label }
      }

      saveOpenCodeConfig(config)

      const savedConfig = loadOpenCodeConfig()
      console.log(chalk.dim(`  ğŸ“ Config saved to: ${getOpenCodeConfigPath()}`))
      console.log(chalk.dim(`  ğŸ“ Default model in config: ${savedConfig.model || 'NOT SET'}`))
      console.log()

      if (savedConfig.model === config.model) {
        console.log(chalk.green(`  âœ“ Default model set to: ${modelRef}`))
      } else {
        console.log(chalk.yellow(`  âš  Config might not have been saved correctly`))
      }
      console.log()
      console.log(chalk.dim('  Starting OpenCodeâ€¦'))
      console.log()

      await spawnOpenCode(['--model', modelRef], providerKey, fcmConfig)
    } else {
      // ğŸ“– NVIDIA NIM not configured -- show install prompt
      console.log(chalk.yellow('  âš  NVIDIA NIM not configured in OpenCode'))
      console.log()
      console.log(chalk.dim('  Starting OpenCode with installation promptâ€¦'))
      console.log()

      const configPath = getOpenCodeConfigPath()
      const installPrompt = `Please install NVIDIA NIM provider in OpenCode by adding this to ${configPath}:

{
  "provider": {
    "nvidia": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "NVIDIA NIM",
      "options": {
        "baseURL": "https://integrate.api.nvidia.com/v1",
        "apiKey": "{env:NVIDIA_API_KEY}"
      }
    }
  }
}

${isWindows ? 'set NVIDIA_API_KEY=your_key_here' : 'export NVIDIA_API_KEY=your_key_here'}

After installation, you can use: opencode --model ${modelRef}`

      console.log(chalk.cyan(installPrompt))
      console.log()
      console.log(chalk.dim('  Starting OpenCodeâ€¦'))
      console.log()

      await spawnOpenCode([], providerKey, fcmConfig)
    }
  } else {
    // ğŸ“– Groq: built-in OpenCode provider -- needs provider block with apiKey in opencode.json.
    // ğŸ“– Cerebras: NOT built-in -- needs @ai-sdk/openai-compatible + baseURL, like NVIDIA.
    // ğŸ“– Both need the model registered in provider.<key>.models so OpenCode can find it.
    console.log(chalk.green(`  ğŸš€ Setting ${chalk.bold(model.label)} as defaultâ€¦`))
    console.log(chalk.dim(`  Model: ${modelRef}`))
    console.log()

    const config = loadOpenCodeConfig()
    const backupPath = `${getOpenCodeConfigPath()}.backup-${Date.now()}`

    if (existsSync(getOpenCodeConfigPath())) {
      copyFileSync(getOpenCodeConfigPath(), backupPath)
      console.log(chalk.dim(`  ğŸ’¾ Backup: ${backupPath}`))
    }

    // ğŸ“– Ensure the provider block exists in config â€” create it if missing
    if (!config.provider) config.provider = {}
    if (!config.provider[providerKey]) {
      if (providerKey === 'groq') {
        // ğŸ“– Groq is a built-in OpenCode provider â€” just needs apiKey options, no npm package
        config.provider.groq = {
          options: { apiKey: '{env:GROQ_API_KEY}' },
          models: {}
        }
      } else if (providerKey === 'cerebras') {
        // ğŸ“– Cerebras is OpenAI-compatible â€” needs npm package and baseURL like NVIDIA
        config.provider.cerebras = {
          npm: '@ai-sdk/openai-compatible',
          name: 'Cerebras',
          options: {
            baseURL: 'https://api.cerebras.ai/v1',
            apiKey: '{env:CEREBRAS_API_KEY}'
          },
          models: {}
        }
      } else if (providerKey === 'sambanova') {
        // ğŸ“– SambaNova is OpenAI-compatible â€” uses @ai-sdk/openai-compatible with their base URL
        config.provider.sambanova = {
          npm: '@ai-sdk/openai-compatible',
          name: 'SambaNova',
          options: {
            baseURL: 'https://api.sambanova.ai/v1',
            apiKey: '{env:SAMBANOVA_API_KEY}'
          },
          models: {}
        }
      } else if (providerKey === 'openrouter') {
        config.provider.openrouter = {
          npm: '@ai-sdk/openai-compatible',
          name: 'OpenRouter',
          options: {
            baseURL: 'https://openrouter.ai/api/v1',
            apiKey: '{env:OPENROUTER_API_KEY}'
          },
          models: {}
        }
      } else if (providerKey === 'codestral') {
        config.provider.codestral = {
          npm: '@ai-sdk/openai-compatible',
          name: 'Mistral Codestral',
          options: {
            baseURL: 'https://codestral.mistral.ai/v1',
            apiKey: '{env:CODESTRAL_API_KEY}'
          },
          models: {}
        }
      } else if (providerKey === 'hyperbolic') {
        config.provider.hyperbolic = {
          npm: '@ai-sdk/openai-compatible',
          name: 'Hyperbolic',
          options: {
            baseURL: 'https://api.hyperbolic.xyz/v1',
            apiKey: '{env:HYPERBOLIC_API_KEY}'
          },
          models: {}
        }
      } else if (providerKey === 'scaleway') {
        config.provider.scaleway = {
          npm: '@ai-sdk/openai-compatible',
          name: 'Scaleway',
          options: {
            baseURL: 'https://api.scaleway.ai/v1',
            apiKey: '{env:SCALEWAY_API_KEY}'
          },
          models: {}
        }
      } else if (providerKey === 'googleai') {
        config.provider.googleai = {
          npm: '@ai-sdk/openai-compatible',
          name: 'Google AI Studio',
          options: {
            baseURL: 'https://generativelanguage.googleapis.com/v1beta/openai',
            apiKey: '{env:GOOGLE_API_KEY}'
          },
          models: {}
        }
      }
    }

    // ğŸ“– Register the model in the provider's models section
    // ğŸ“– Only register custom models -- skip if the model maps to a built-in OpenCode ID
    const isBuiltinMapped = OPENCODE_MODEL_MAP[providerKey]?.[model.modelId]
    if (!isBuiltinMapped) {
      if (!config.provider[providerKey].models) config.provider[providerKey].models = {}
      config.provider[providerKey].models[ocModelId] = { name: model.label }
    }

    config.model = modelRef
    saveOpenCodeConfig(config)

    const savedConfig = loadOpenCodeConfig()
    console.log(chalk.dim(`  ğŸ“ Config saved to: ${getOpenCodeConfigPath()}`))
    console.log(chalk.dim(`  ğŸ“ Default model in config: ${savedConfig.model || 'NOT SET'}`))
    console.log()

    if (savedConfig.model === config.model) {
      console.log(chalk.green(`  âœ“ Default model set to: ${modelRef}`))
    } else {
      console.log(chalk.yellow(`  âš  Config might not have been saved correctly`))
    }
    console.log()
    console.log(chalk.dim('  Starting OpenCodeâ€¦'))
    console.log()

    await spawnOpenCode(['--model', modelRef], providerKey, fcmConfig)
  }
}

// â”€â”€â”€ Start OpenCode Desktop â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– startOpenCodeDesktop: Same config logic as startOpenCode, but opens the Desktop app.
// ğŸ“– OpenCode Desktop shares config at the same location as CLI.
// ğŸ“– Handles all 3 providers: nvidia (needs custom provider config), groq & cerebras (built-in).
// ğŸ“– No need to wait for exit â€” Desktop app stays open independently.
async function startOpenCodeDesktop(model, fcmConfig) {
  const providerKey = model.providerKey ?? 'nvidia'
  // ğŸ“– Map model ID to OpenCode's built-in ID if it differs from our source ID
  const ocModelId = getOpenCodeModelId(providerKey, model.modelId)
  const modelRef = `${providerKey}/${ocModelId}`

  // ğŸ“– Helper to open the Desktop app based on platform
  const launchDesktop = async () => {
    const { exec } = await import('child_process')
    let command
    if (isMac) {
      command = 'open -a OpenCode'
    } else if (isWindows) {
      command = 'start "" "%LOCALAPPDATA%\\Programs\\OpenCode\\OpenCode.exe" 2>nul || start "" "%PROGRAMFILES%\\OpenCode\\OpenCode.exe" 2>nul || start OpenCode'
    } else if (isLinux) {
      command = `opencode-desktop --model ${modelRef} 2>/dev/null || flatpak run ai.opencode.OpenCode --model ${modelRef} 2>/dev/null || snap run opencode --model ${modelRef} 2>/dev/null || xdg-open /usr/share/applications/opencode.desktop 2>/dev/null || echo "OpenCode not found"`
    }
    exec(command, (err) => {
      if (err) {
        console.error(chalk.red('  âœ— Could not open OpenCode Desktop'))
        if (isWindows) {
          console.error(chalk.dim('    Make sure OpenCode is installed from https://opencode.ai'))
        } else if (isLinux) {
          console.error(chalk.dim('    Install via: snap install opencode OR flatpak install ai.opencode.OpenCode'))
          console.error(chalk.dim('    Or download from https://opencode.ai'))
        } else {
          console.error(chalk.dim('    Is it installed at /Applications/OpenCode.app?'))
        }
      }
    })
  }

  if (providerKey === 'nvidia') {
    // ğŸ“– NVIDIA NIM needs a custom provider block in OpenCode config (not built-in)
    const hasNim = checkNvidiaNimConfig()

    if (hasNim) {
      console.log(chalk.green(`  ğŸ–¥ Setting ${chalk.bold(model.label)} as default for OpenCode Desktopâ€¦`))
      console.log(chalk.dim(`  Model: ${modelRef}`))
      console.log()

      const config = loadOpenCodeConfig()
      const backupPath = `${getOpenCodeConfigPath()}.backup-${Date.now()}`

      if (existsSync(getOpenCodeConfigPath())) {
        copyFileSync(getOpenCodeConfigPath(), backupPath)
        console.log(chalk.dim(`  ğŸ’¾ Backup: ${backupPath}`))
      }

      config.model = modelRef

      if (config.provider?.nvidia) {
        if (!config.provider.nvidia.models) config.provider.nvidia.models = {}
        config.provider.nvidia.models[ocModelId] = { name: model.label }
      }

      saveOpenCodeConfig(config)

      const savedConfig = loadOpenCodeConfig()
      console.log(chalk.dim(`  ğŸ“ Config saved to: ${getOpenCodeConfigPath()}`))
      console.log(chalk.dim(`  ğŸ“ Default model in config: ${savedConfig.model || 'NOT SET'}`))
      console.log()

      if (savedConfig.model === config.model) {
        console.log(chalk.green(`  âœ“ Default model set to: ${modelRef}`))
      } else {
        console.log(chalk.yellow(`  âš  Config might not have been saved correctly`))
      }
      console.log()
      console.log(chalk.dim('  Opening OpenCode Desktopâ€¦'))
      console.log()

      await launchDesktop()
    } else {
      console.log(chalk.yellow('  âš  NVIDIA NIM not configured in OpenCode'))
      console.log(chalk.dim('  Please configure it first. Config is shared between CLI and Desktop.'))
      console.log()

      const configPath = getOpenCodeConfigPath()
      const installPrompt = `Add this to ${configPath}:

{
  "provider": {
    "nvidia": {
      "npm": "@ai-sdk/openai-compatible",
      "name": "NVIDIA NIM",
      "options": {
        "baseURL": "https://integrate.api.nvidia.com/v1",
        "apiKey": "{env:NVIDIA_API_KEY}"
      }
    }
  }
}

${isWindows ? 'set NVIDIA_API_KEY=your_key_here' : 'export NVIDIA_API_KEY=your_key_here'}`
      console.log(chalk.cyan(installPrompt))
      console.log()
    }
  } else {
    // ğŸ“– Groq: built-in OpenCode provider â€” needs provider block with apiKey in opencode.json.
    // ğŸ“– Cerebras: NOT built-in â€” needs @ai-sdk/openai-compatible + baseURL, like NVIDIA.
    // ğŸ“– Both need the model registered in provider.<key>.models so OpenCode can find it.
    console.log(chalk.green(`  ğŸ–¥ Setting ${chalk.bold(model.label)} as default for OpenCode Desktopâ€¦`))
    console.log(chalk.dim(`  Model: ${modelRef}`))
    console.log()

    const config = loadOpenCodeConfig()
    const backupPath = `${getOpenCodeConfigPath()}.backup-${Date.now()}`

    if (existsSync(getOpenCodeConfigPath())) {
      copyFileSync(getOpenCodeConfigPath(), backupPath)
      console.log(chalk.dim(`  ğŸ’¾ Backup: ${backupPath}`))
    }

    // ğŸ“– Ensure the provider block exists in config â€” create it if missing
    if (!config.provider) config.provider = {}
    if (!config.provider[providerKey]) {
      if (providerKey === 'groq') {
        config.provider.groq = {
          options: { apiKey: '{env:GROQ_API_KEY}' },
          models: {}
        }
      } else if (providerKey === 'cerebras') {
        config.provider.cerebras = {
          npm: '@ai-sdk/openai-compatible',
          name: 'Cerebras',
          options: {
            baseURL: 'https://api.cerebras.ai/v1',
            apiKey: '{env:CEREBRAS_API_KEY}'
          },
          models: {}
        }
      } else if (providerKey === 'sambanova') {
        // ğŸ“– SambaNova is OpenAI-compatible â€” uses @ai-sdk/openai-compatible with their base URL
        config.provider.sambanova = {
          npm: '@ai-sdk/openai-compatible',
          name: 'SambaNova',
          options: {
            baseURL: 'https://api.sambanova.ai/v1',
            apiKey: '{env:SAMBANOVA_API_KEY}'
          },
          models: {}
        }
      } else if (providerKey === 'openrouter') {
        config.provider.openrouter = {
          npm: '@ai-sdk/openai-compatible',
          name: 'OpenRouter',
          options: {
            baseURL: 'https://openrouter.ai/api/v1',
            apiKey: '{env:OPENROUTER_API_KEY}'
          },
          models: {}
        }
      } else if (providerKey === 'codestral') {
        config.provider.codestral = {
          npm: '@ai-sdk/openai-compatible',
          name: 'Mistral Codestral',
          options: {
            baseURL: 'https://codestral.mistral.ai/v1',
            apiKey: '{env:CODESTRAL_API_KEY}'
          },
          models: {}
        }
      } else if (providerKey === 'hyperbolic') {
        config.provider.hyperbolic = {
          npm: '@ai-sdk/openai-compatible',
          name: 'Hyperbolic',
          options: {
            baseURL: 'https://api.hyperbolic.xyz/v1',
            apiKey: '{env:HYPERBOLIC_API_KEY}'
          },
          models: {}
        }
      } else if (providerKey === 'scaleway') {
        config.provider.scaleway = {
          npm: '@ai-sdk/openai-compatible',
          name: 'Scaleway',
          options: {
            baseURL: 'https://api.scaleway.ai/v1',
            apiKey: '{env:SCALEWAY_API_KEY}'
          },
          models: {}
        }
      } else if (providerKey === 'googleai') {
        config.provider.googleai = {
          npm: '@ai-sdk/openai-compatible',
          name: 'Google AI Studio',
          options: {
            baseURL: 'https://generativelanguage.googleapis.com/v1beta/openai',
            apiKey: '{env:GOOGLE_API_KEY}'
          },
          models: {}
        }
      }
    }

    // ğŸ“– Register the model in the provider's models section
    // ğŸ“– Only register custom models -- skip if the model maps to a built-in OpenCode ID
    const isBuiltinMapped = OPENCODE_MODEL_MAP[providerKey]?.[model.modelId]
    if (!isBuiltinMapped) {
      if (!config.provider[providerKey].models) config.provider[providerKey].models = {}
      config.provider[providerKey].models[ocModelId] = { name: model.label }
    }

    config.model = modelRef
    saveOpenCodeConfig(config)

    const savedConfig = loadOpenCodeConfig()
    console.log(chalk.dim(`  ğŸ“ Config saved to: ${getOpenCodeConfigPath()}`))
    console.log(chalk.dim(`  ğŸ“ Default model in config: ${savedConfig.model || 'NOT SET'}`))
    console.log()

    if (savedConfig.model === config.model) {
      console.log(chalk.green(`  âœ“ Default model set to: ${modelRef}`))
    } else {
      console.log(chalk.yellow(`  âš  Config might not have been saved correctly`))
    }
    console.log()
    console.log(chalk.dim('  Opening OpenCode Desktopâ€¦'))
    console.log()

    await launchDesktop()
  }
}

// â”€â”€â”€ OpenClaw integration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– OpenClaw config: ~/.openclaw/openclaw.json (JSON format, may be JSON5 in newer versions)
// ğŸ“– To set a model: set agents.defaults.model.primary = "nvidia/model-id"
// ğŸ“– Providers section uses baseUrl + apiKey + api: "openai-completions" format
// ğŸ“– See: https://docs.openclaw.ai/gateway/configuration
const OPENCLAW_CONFIG = join(homedir(), '.openclaw', 'openclaw.json')

function loadOpenClawConfig() {
  if (!existsSync(OPENCLAW_CONFIG)) return {}
  try {
    // ğŸ“– JSON.parse works for standard JSON; OpenClaw may use JSON5 but base config is valid JSON
    return JSON.parse(readFileSync(OPENCLAW_CONFIG, 'utf8'))
  } catch {
    return {}
  }
}

function saveOpenClawConfig(config) {
  const dir = join(homedir(), '.openclaw')
  if (!existsSync(dir)) {
    mkdirSync(dir, { recursive: true })
  }
  writeFileSync(OPENCLAW_CONFIG, JSON.stringify(config, null, 2))
}

// ğŸ“– startOpenClaw: sets the selected NVIDIA NIM model as default in OpenClaw config.
// ğŸ“– Also ensures the nvidia provider block is present with the NIM base URL.
// ğŸ“– Does NOT launch OpenClaw â€” OpenClaw runs as a daemon, so config changes are picked up on restart.
async function startOpenClaw(model, apiKey) {
  console.log(chalk.rgb(255, 100, 50)(`  ğŸ¦ Setting ${chalk.bold(model.label)} as OpenClaw defaultâ€¦`))
  console.log(chalk.dim(`  Model: nvidia/${model.modelId}`))
  console.log()

  const config = loadOpenClawConfig()

  // ğŸ“– Backup existing config before touching it
  if (existsSync(OPENCLAW_CONFIG)) {
    const backupPath = `${OPENCLAW_CONFIG}.backup-${Date.now()}`
    copyFileSync(OPENCLAW_CONFIG, backupPath)
    console.log(chalk.dim(`  ğŸ’¾ Backup: ${backupPath}`))
  }

  // ğŸ“– Patch models.json to add all NVIDIA models (fixes "not allowed" errors)
  const patchResult = patchOpenClawModelsJson()
  if (patchResult.wasPatched) {
    console.log(chalk.dim(`  âœ¨ Added ${patchResult.added} NVIDIA models to allowlist (${patchResult.total} total)`))
    if (patchResult.backup) {
      console.log(chalk.dim(`  ğŸ’¾ models.json backup: ${patchResult.backup}`))
    }
  }

  // ğŸ“– Ensure models.providers section exists with nvidia NIM block.
  // ğŸ“– Per OpenClaw docs (docs.openclaw.ai/providers/nvidia), providers MUST be nested under
  // ğŸ“– "models.providers", NOT at the config root. Root-level "providers" is ignored by OpenClaw.
  // ğŸ“– API key is NOT stored in the provider block â€” it's read from env var NVIDIA_API_KEY.
  // ğŸ“– If needed, it can be stored under the root "env" key: { env: { NVIDIA_API_KEY: "nvapi-..." } }
  if (!config.models) config.models = {}
  if (!config.models.providers) config.models.providers = {}
  if (!config.models.providers.nvidia) {
    config.models.providers.nvidia = {
      baseUrl: 'https://integrate.api.nvidia.com/v1',
      api: 'openai-completions',
      models: [],
    }
    console.log(chalk.dim('  â• Added nvidia provider block to OpenClaw config (models.providers.nvidia)'))
  }
  // ğŸ“– Ensure models array exists even if the provider block was created by an older version
  if (!Array.isArray(config.models.providers.nvidia.models)) {
    config.models.providers.nvidia.models = []
  }

  // ğŸ“– Store API key in the root "env" section so OpenClaw can read it as NVIDIA_API_KEY env var.
  // ğŸ“– Only writes if not already set to avoid overwriting an existing key.
  const resolvedKey = apiKey || process.env.NVIDIA_API_KEY
  if (resolvedKey) {
    if (!config.env) config.env = {}
    if (!config.env.NVIDIA_API_KEY) {
      config.env.NVIDIA_API_KEY = resolvedKey
      console.log(chalk.dim('  ğŸ”‘ Stored NVIDIA_API_KEY in config env section'))
    }
  }

  // ğŸ“– Set as the default primary model for all agents.
  // ğŸ“– Format: "provider/model-id" â€” e.g. "nvidia/deepseek-ai/deepseek-v3.2"
  // ğŸ“– Set as the default primary model for all agents.
  // ğŸ“– Format: "provider/model-id" â€” e.g. "nvidia/deepseek-ai/deepseek-v3.2"
  if (!config.agents) config.agents = {}
  if (!config.agents.defaults) config.agents.defaults = {}
  if (!config.agents.defaults.model) config.agents.defaults.model = {}
  config.agents.defaults.model.primary = `nvidia/${model.modelId}`

  // ğŸ“– REQUIRED: OpenClaw requires the model to be explicitly listed in agents.defaults.models
  // ğŸ“– (the allowlist). Without this entry, OpenClaw rejects the model with "not allowed".
  // ğŸ“– See: https://docs.openclaw.ai/gateway/configuration-reference
  if (!config.agents.defaults.models) config.agents.defaults.models = {}
  config.agents.defaults.models[`nvidia/${model.modelId}`] = {}

  saveOpenClawConfig(config)

  console.log(chalk.rgb(255, 140, 0)(`  âœ“ Default model set to: nvidia/${model.modelId}`))
  console.log()
  console.log(chalk.dim('  ğŸ“„ Config updated: ' + OPENCLAW_CONFIG))
  console.log()
  // ğŸ“– "openclaw restart" does NOT exist. The gateway auto-reloads on config file changes.
  // ğŸ“– To apply manually: use "openclaw models set" or "openclaw configure"
  // ğŸ“– See: https://docs.openclaw.ai/gateway/configuration
  console.log(chalk.dim('  ğŸ’¡ OpenClaw will reload config automatically (gateway.reload.mode).'))
  console.log(chalk.dim('     To apply manually: openclaw models set nvidia/' + model.modelId))
  console.log(chalk.dim('     Or run the setup wizard: openclaw configure'))
  console.log()
}

// â”€â”€â”€ Helper function to find best model after analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// ğŸ“– findBestModel is imported from lib/utils.js

// â”€â”€â”€ Function to run in fiable mode (10-second analysis then output best model) â”€â”€
async function runFiableMode(config) {
  console.log(chalk.cyan('  âš¡ Analyzing models for reliability (10 seconds)...'))
  console.log()

  // ğŸ“– Only include models from enabled providers that have API keys
  let results = MODELS
    .filter(([,,,,,providerKey]) => {
      return isProviderEnabled(config, providerKey) && getApiKey(config, providerKey)
    })
    .map(([modelId, label, tier, sweScore, ctx, providerKey], i) => ({
      idx: i + 1, modelId, label, tier, sweScore, ctx, providerKey,
      status: 'pending',
      pings: [],
      httpCode: null,
    }))

  const startTime = Date.now()
  const analysisDuration = 10000 // 10 seconds

  // ğŸ“– Run initial pings using per-provider API key and URL
  const pingPromises = results.map(r => {
    const rApiKey = getApiKey(config, r.providerKey)
    const url = sources[r.providerKey]?.url
    return ping(rApiKey, r.modelId, url).then(({ code, ms }) => {
      r.pings.push({ ms, code })
      if (code === '200') {
        r.status = 'up'
      } else if (code === '000') {
        r.status = 'timeout'
      } else {
        r.status = 'down'
        r.httpCode = code
      }
    })
  })

  await Promise.allSettled(pingPromises)

  // ğŸ“– Continue pinging for the remaining time
  const remainingTime = Math.max(0, analysisDuration - (Date.now() - startTime))
  if (remainingTime > 0) {
    await new Promise(resolve => setTimeout(resolve, remainingTime))
  }

  // ğŸ“– Find best model
  const best = findBestModel(results)

  if (!best) {
    console.log(chalk.red('  âœ– No reliable model found'))
    process.exit(1)
  }

  // ğŸ“– Output in format: providerName/modelId
  const providerName = sources[best.providerKey]?.name ?? best.providerKey ?? 'nvidia'
  console.log(chalk.green(`  âœ“ Most reliable model:`))
  console.log(chalk.bold(`    ${providerName}/${best.modelId}`))
  console.log()
  console.log(chalk.dim(`  ğŸ“Š Stats:`))
  console.log(chalk.dim(`    Avg ping: ${getAvg(best)}ms`))
  console.log(chalk.dim(`    Uptime: ${getUptime(best)}%`))
  console.log(chalk.dim(`    Status: ${best.status === 'up' ? 'âœ… UP' : 'âŒ DOWN'}`))

  process.exit(0)
}

// ğŸ“– filterByTier and TIER_LETTER_MAP are imported from lib/utils.js
// ğŸ“– Wrapper that exits on invalid tier (utils version returns null instead)
function filterByTierOrExit(results, tierLetter) {
  const filtered = filterByTier(results, tierLetter)
  if (filtered === null) {
    console.error(chalk.red(`  âœ– Unknown tier "${tierLetter}". Valid tiers: S, A, B, C`))
    process.exit(1)
  }
  return filtered
}

async function main() {
  const cliArgs = parseArgs(process.argv)

  // Validate --tier early, before entering alternate screen
  if (cliArgs.tierFilter && !TIER_LETTER_MAP[cliArgs.tierFilter]) {
    console.error(chalk.red(`  Unknown tier "${cliArgs.tierFilter}". Valid tiers: S, A, B, C`))
    process.exit(1)
  }

  // ğŸ“– Load JSON config (auto-migrates old plain-text ~/.free-coding-models if needed)
  const config = loadConfig()

  // ğŸ“– Check if any provider has a key â€” if not, run the first-time setup wizard
  const hasAnyKey = Object.keys(sources).some(pk => !!getApiKey(config, pk))

  if (!hasAnyKey) {
    const result = await promptApiKey(config)
    if (!result) {
      console.log()
      console.log(chalk.red('  âœ– No API key provided.'))
      console.log(chalk.dim('  Run `free-coding-models` again or set NVIDIA_API_KEY / GROQ_API_KEY / CEREBRAS_API_KEY.'))
      console.log()
      process.exit(1)
    }
  }

  // ğŸ“– Backward-compat: keep apiKey var for startOpenClaw() which still needs it
  let apiKey = getApiKey(config, 'nvidia')

  // ğŸ“– Check for updates in the background
  let latestVersion = null
  try {
    latestVersion = await checkForUpdate()
  } catch {
    // Silently fail - don't block the app if npm registry is unreachable
  }

  // ğŸ“– Default mode: OpenCode CLI
  let mode = 'opencode'

  // ğŸ“– Show update notification menu if a new version is available
  if (latestVersion) {
    const action = await promptUpdateNotification(latestVersion)
    if (action === 'update') {
      runUpdate(latestVersion)
      return // runUpdate will restart the process
    } else if (action === 'changelogs') {
      console.log()
      console.log(chalk.cyan('  Opening changelog in browser...'))
      console.log()
      const { execSync } = require('child_process')
      const changelogUrl = 'https://github.com/vava-nessa/free-coding-models/releases'
      try {
        if (isMac) {
          execSync(`open "${changelogUrl}"`, { stdio: 'ignore' })
        } else if (isWindows) {
          execSync(`start "" "${changelogUrl}"`, { stdio: 'ignore' })
        } else {
          execSync(`xdg-open "${changelogUrl}"`, { stdio: 'ignore' })
        }
      } catch {
        console.log(chalk.dim(`  Could not open browser. Visit: ${changelogUrl}`))
      }
    }
    // If action is null (Continue without update) or changelogs, proceed to main app
  }

  // ğŸ“– Build results from MODELS â€” only include enabled providers
  // ğŸ“– Each result gets providerKey so ping() knows which URL + API key to use
  let results = MODELS
    .filter(([,,,,,providerKey]) => isProviderEnabled(config, providerKey))
    .map(([modelId, label, tier, sweScore, ctx, providerKey], i) => ({
      idx: i + 1, modelId, label, tier, sweScore, ctx, providerKey,
      status: 'pending',
      pings: [],  // ğŸ“– All ping results (ms or 'TIMEOUT')
      httpCode: null,
      hidden: false,  // ğŸ“– Simple flag to hide/show models
    }))

  // ğŸ“– Clamp scrollOffset so cursor is always within the visible viewport window.
  // ğŸ“– Called after every cursor move, sort change, and terminal resize.
  const adjustScrollOffset = (st) => {
    const total = st.visibleSorted ? st.visibleSorted.length : st.results.filter(r => !r.hidden).length
    let maxSlots = st.terminalRows - 10  // 5 header + 5 footer
    if (maxSlots < 1) maxSlots = 1
    if (total <= maxSlots) { st.scrollOffset = 0; return }
    // Ensure cursor is not above the visible window
    if (st.cursor < st.scrollOffset) {
      st.scrollOffset = st.cursor
    }
    // Ensure cursor is not below the visible window
    // Account for indicator lines eating into model slots
    const hasAbove = st.scrollOffset > 0
    const tentativeBelow = st.scrollOffset + maxSlots - (hasAbove ? 1 : 0) < total
    const modelSlots = maxSlots - (hasAbove ? 1 : 0) - (tentativeBelow ? 1 : 0)
    if (st.cursor >= st.scrollOffset + modelSlots) {
      st.scrollOffset = st.cursor - modelSlots + 1
    }
    // Final clamp
    const maxOffset = Math.max(0, total - maxSlots)
    if (st.scrollOffset > maxOffset) st.scrollOffset = maxOffset
    if (st.scrollOffset < 0) st.scrollOffset = 0
  }

  // ğŸ“– Add interactive selection state - cursor index and user's choice
  // ğŸ“– sortColumn: 'rank'|'tier'|'origin'|'model'|'ping'|'avg'|'status'|'verdict'|'uptime'
  // ğŸ“– sortDirection: 'asc' (default) or 'desc'
  // ğŸ“– pingInterval: current interval in ms (default 2000, adjustable with W/X keys)
  // ğŸ“– tierFilter: current tier filter letter (null = all, 'S' = S+/S, 'A' = A+/A/A-, etc.)
  const state = {
    results,
    pendingPings: 0,
    frame: 0,
    cursor: 0,
    selectedModel: null,
    sortColumn: 'avg',
    sortDirection: 'asc',
    pingInterval: PING_INTERVAL,  // ğŸ“– Track current interval for W/X keys
    lastPingTime: Date.now(),     // ğŸ“– Track when last ping cycle started
    mode,                         // ğŸ“– 'opencode' or 'openclaw' â€” controls Enter action
    scrollOffset: 0,              // ğŸ“– First visible model index in viewport
    terminalRows: process.stdout.rows || 24,  // ğŸ“– Current terminal height
    // ğŸ“– Settings screen state (P key opens it)
    settingsOpen: false,          // ğŸ“– Whether settings overlay is active
    settingsCursor: 0,            // ğŸ“– Which provider row is selected in settings
    settingsEditMode: false,      // ğŸ“– Whether we're in inline key editing mode
    settingsEditBuffer: '',       // ğŸ“– Typed characters for the API key being edited
    settingsTestResults: {},      // ğŸ“– { providerKey: 'pending'|'ok'|'fail'|null }
    config,                       // ğŸ“– Live reference to the config object (updated on save)
    visibleSorted: [],            // ğŸ“– Cached visible+sorted models â€” shared between render loop and key handlers
    helpVisible: false,           // ğŸ“– Whether the help overlay (K key) is active
  }

  // ğŸ“– Re-clamp viewport on terminal resize
  process.stdout.on('resize', () => {
    state.terminalRows = process.stdout.rows || 24
    adjustScrollOffset(state)
  })

  // ğŸ“– Enter alternate screen â€” animation runs here, zero scrollback pollution
  process.stdout.write(ALT_ENTER)

  // ğŸ“– Ensure we always leave alt screen cleanly (Ctrl+C, crash, normal exit)
  const exit = (code = 0) => {
    clearInterval(ticker)
    clearTimeout(state.pingIntervalObj)
    process.stdout.write(ALT_LEAVE)
    process.exit(code)
  }
  process.on('SIGINT',  () => exit(0))
  process.on('SIGTERM', () => exit(0))

  // ğŸ“– Tier filtering system - cycles through each individual tier one by one
  // ğŸ“– 0=All, 1=S+, 2=S, 3=A+, 4=A, 5=A-, 6=B+, 7=B, 8=C
  const TIER_CYCLE = [null, 'S+', 'S', 'A+', 'A', 'A-', 'B+', 'B', 'C']
  let tierFilterMode = 0

  // ğŸ“– originFilterMode: index into ORIGIN_CYCLE, 0=All, then each provider key in order
  const ORIGIN_CYCLE = [null, ...Object.keys(sources)]
  let originFilterMode = 0

  function applyTierFilter() {
    const activeTier = TIER_CYCLE[tierFilterMode]
    const activeOrigin = ORIGIN_CYCLE[originFilterMode]
    state.results.forEach(r => {
      // ğŸ“– Apply both tier and origin filters â€” model is hidden if it fails either
      const tierHide = activeTier !== null && r.tier !== activeTier
      const originHide = activeOrigin !== null && r.providerKey !== activeOrigin
      r.hidden = tierHide || originHide
    })
    return state.results
  }

  // â”€â”€â”€ Settings screen renderer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ğŸ“– renderSettings: Draw the settings overlay in the alt screen buffer.
  // ğŸ“– Shows all providers with their API key (masked) + enabled state.
  // ğŸ“– When in edit mode (settingsEditMode=true), shows an inline input field.
  // ğŸ“– Key "T" in settings = test API key for selected provider.
  function renderSettings() {
    const providerKeys = Object.keys(sources)
    const EL = '\x1b[K'
    const lines = []

    lines.push('')
    lines.push(`  ${chalk.bold('âš™  Settings')}  ${chalk.dim('â€” free-coding-models v' + LOCAL_VERSION)}`)
    lines.push('')
    lines.push(`  ${chalk.bold('Providers')}`)
    lines.push('')

    for (let i = 0; i < providerKeys.length; i++) {
      const pk = providerKeys[i]
      const src = sources[pk]
      const isCursor = i === state.settingsCursor
      const enabled = isProviderEnabled(state.config, pk)
      const keyVal = state.config.apiKeys?.[pk] ?? ''

      // ğŸ“– Build API key display â€” mask most chars, show last 4
      let keyDisplay
      if (state.settingsEditMode && isCursor) {
        // ğŸ“– Inline editing: show typed buffer with cursor indicator
        keyDisplay = chalk.cyanBright(`${state.settingsEditBuffer || ''}â–`)
      } else if (keyVal) {
        const visible = keyVal.slice(-4)
        const masked = 'â€¢'.repeat(Math.min(16, Math.max(4, keyVal.length - 4)))
        keyDisplay = chalk.dim(masked + visible)
      } else {
        keyDisplay = chalk.dim('(no key set)')
      }

      // ğŸ“– Test result badge
      const testResult = state.settingsTestResults[pk]
      let testBadge = chalk.dim('[Test â€”]')
      if (testResult === 'pending') testBadge = chalk.yellow('[Testingâ€¦]')
      else if (testResult === 'ok')   testBadge = chalk.greenBright('[Test âœ…]')
      else if (testResult === 'fail') testBadge = chalk.red('[Test âŒ]')

      const enabledBadge = enabled ? chalk.greenBright('âœ…') : chalk.dim('â¬œ')
      const providerName = chalk.bold(src.name.padEnd(10))
      const bullet = isCursor ? chalk.bold.cyan('  â¯ ') : chalk.dim('    ')

      const row = `${bullet}[ ${enabledBadge} ] ${providerName}  ${keyDisplay.padEnd(30)}  ${testBadge}`
      lines.push(isCursor ? chalk.bgRgb(30, 30, 60)(row) : row)
    }

    lines.push('')
    if (state.settingsEditMode) {
      lines.push(chalk.dim('  Type API key  â€¢  Enter Save  â€¢  Esc Cancel'))
    } else {
      lines.push(chalk.dim('  â†‘â†“ Navigate  â€¢  Enter Edit key  â€¢  Space Toggle enabled  â€¢  T Test key  â€¢  Esc Close'))
    }
    lines.push('')

    const cleared = lines.map(l => l + EL)
    const remaining = state.terminalRows > 0 ? Math.max(0, state.terminalRows - cleared.length) : 0
    for (let i = 0; i < remaining; i++) cleared.push(EL)
    return cleared.join('\n')
  }

  // â”€â”€â”€ Help overlay renderer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ğŸ“– renderHelp: Draw the help overlay listing all key bindings.
  // ğŸ“– Toggled with K key. Gives users a quick reference without leaving the TUI.
  function renderHelp() {
    const EL = '\x1b[K'
    const lines = []
    lines.push('')
    lines.push(`  ${chalk.bold('â“ Keyboard Shortcuts')}  ${chalk.dim('â€” press K or Esc to close')}`)
    lines.push('')
    lines.push(`  ${chalk.bold('Navigation')}`)
    lines.push(`  ${chalk.yellow('â†‘â†“')}           Navigate rows`)
    lines.push(`  ${chalk.yellow('Enter')}        Select model and launch`)
    lines.push('')
    lines.push(`  ${chalk.bold('Sorting')}`)
    lines.push(`  ${chalk.yellow('R')} Rank  ${chalk.yellow('Y')} Tier  ${chalk.yellow('O')} Origin  ${chalk.yellow('M')} Model`)
    lines.push(`  ${chalk.yellow('L')} Latest ping  ${chalk.yellow('A')} Avg ping  ${chalk.yellow('S')} SWE-bench score`)
    lines.push(`  ${chalk.yellow('C')} Context window  ${chalk.yellow('H')} Health  ${chalk.yellow('V')} Verdict  ${chalk.yellow('U')} Uptime`)
    lines.push('')
    lines.push(`  ${chalk.bold('Filters')}`)
    lines.push(`  ${chalk.yellow('T')}  Cycle tier filter  ${chalk.dim('(All â†’ S+ â†’ S â†’ A+ â†’ A â†’ A- â†’ B+ â†’ B â†’ C â†’ All)')}`)
    lines.push(`  ${chalk.yellow('N')}  Cycle origin filter  ${chalk.dim('(All â†’ NIM â†’ Groq â†’ Cerebras â†’ ... each provider â†’ All)')}`)
    lines.push('')
    lines.push(`  ${chalk.bold('Controls')}`)
    lines.push(`  ${chalk.yellow('W')}  Decrease ping interval (faster)`)
    lines.push(`  ${chalk.yellow('X')}  Increase ping interval (slower)`)
    lines.push(`  ${chalk.yellow('Z')}  Cycle launch mode  ${chalk.dim('(OpenCode CLI â†’ OpenCode Desktop â†’ OpenClaw)')}`)
    lines.push(`  ${chalk.yellow('P')}  Open settings  ${chalk.dim('(manage API keys per provider, enable/disable, test)')}`)
    lines.push(`  ${chalk.yellow('K')} / ${chalk.yellow('Esc')}  Show/hide this help`)
    lines.push(`  ${chalk.yellow('Ctrl+C')}  Exit`)
    lines.push('')
    const cleared = lines.map(l => l + EL)
    const remaining = state.terminalRows > 0 ? Math.max(0, state.terminalRows - cleared.length) : 0
    for (let i = 0; i < remaining; i++) cleared.push(EL)
    return cleared.join('\n')
  }

  // â”€â”€â”€ Settings key test helper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  // ğŸ“– Fires a single ping to the selected provider to verify the API key works.
  async function testProviderKey(providerKey) {
    const src = sources[providerKey]
    if (!src) return
    const testKey = getApiKey(state.config, providerKey)
    if (!testKey) { state.settingsTestResults[providerKey] = 'fail'; return }

    // ğŸ“– Use the first model in the provider's list for the test ping
    const testModel = src.models[0]?.[0]
    if (!testModel) { state.settingsTestResults[providerKey] = 'fail'; return }

    state.settingsTestResults[providerKey] = 'pending'
    const { code } = await ping(testKey, testModel, src.url)
    state.settingsTestResults[providerKey] = code === '200' ? 'ok' : 'fail'
  }

  // Apply CLI --tier filter if provided
  if (cliArgs.tierFilter) {
    const allowed = TIER_LETTER_MAP[cliArgs.tierFilter]
    state.results.forEach(r => {
      r.hidden = !allowed.includes(r.tier)
    })
  }

  // ğŸ“– Setup keyboard input for interactive selection during pings
  // ğŸ“– Use readline with keypress event for arrow key handling
  process.stdin.setEncoding('utf8')
  process.stdin.resume()

  let userSelected = null

  const onKeyPress = async (str, key) => {
    if (!key) return

    // ğŸ“– Help overlay: Esc or K closes it â€” handle before everything else so Esc isn't swallowed elsewhere
    if (state.helpVisible && (key.name === 'escape' || key.name === 'k')) {
      state.helpVisible = false
      return
    }

    // â”€â”€â”€ Settings overlay keyboard handling â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if (state.settingsOpen) {
      const providerKeys = Object.keys(sources)

      // ğŸ“– Edit mode: capture typed characters for the API key
      if (state.settingsEditMode) {
        if (key.name === 'return') {
          // ğŸ“– Save the new key and exit edit mode
          const pk = providerKeys[state.settingsCursor]
          const newKey = state.settingsEditBuffer.trim()
          if (newKey) {
            state.config.apiKeys[pk] = newKey
            saveConfig(state.config)
          }
          state.settingsEditMode = false
          state.settingsEditBuffer = ''
        } else if (key.name === 'escape') {
          // ğŸ“– Cancel without saving
          state.settingsEditMode = false
          state.settingsEditBuffer = ''
        } else if (key.name === 'backspace') {
          state.settingsEditBuffer = state.settingsEditBuffer.slice(0, -1)
        } else if (str && !key.ctrl && !key.meta && str.length === 1) {
          // ğŸ“– Append printable character to buffer
          state.settingsEditBuffer += str
        }
        return
      }

      // ğŸ“– Normal settings navigation
      if (key.name === 'escape') {
        // ğŸ“– Close settings â€” rebuild results to reflect provider changes
        state.settingsOpen = false
        // ğŸ“– Rebuild results: add models from newly enabled providers, remove disabled
        results = MODELS
          .filter(([,,,,,pk]) => isProviderEnabled(state.config, pk))
          .map(([modelId, label, tier, sweScore, ctx, providerKey], i) => {
            // ğŸ“– Try to reuse existing result to keep ping history
            const existing = state.results.find(r => r.modelId === modelId && r.providerKey === providerKey)
            if (existing) return existing
            return { idx: i + 1, modelId, label, tier, sweScore, ctx, providerKey, status: 'pending', pings: [], httpCode: null, hidden: false }
          })
        // ğŸ“– Re-index results
        results.forEach((r, i) => { r.idx = i + 1 })
        state.results = results
        adjustScrollOffset(state)
        // ğŸ“– Re-ping all models that were 'noauth' (got 401 without key) but now have a key
        // ğŸ“– This makes the TUI react immediately when a user adds an API key in settings
        state.results.forEach(r => {
          if (r.status === 'noauth' && getApiKey(state.config, r.providerKey)) {
            r.status = 'pending'
            r.pings = []
            r.httpCode = null
            pingModel(r).catch(() => {})
          }
        })
        return
      }

      if (key.name === 'up' && state.settingsCursor > 0) {
        state.settingsCursor--
        return
      }

      if (key.name === 'down' && state.settingsCursor < providerKeys.length - 1) {
        state.settingsCursor++
        return
      }

      if (key.name === 'return') {
        // ğŸ“– Enter edit mode for the selected provider's key
        const pk = providerKeys[state.settingsCursor]
        state.settingsEditBuffer = state.config.apiKeys?.[pk] ?? ''
        state.settingsEditMode = true
        return
      }

      if (key.name === 'space') {
        // ğŸ“– Toggle enabled/disabled for selected provider
        const pk = providerKeys[state.settingsCursor]
        if (!state.config.providers) state.config.providers = {}
        if (!state.config.providers[pk]) state.config.providers[pk] = { enabled: true }
        state.config.providers[pk].enabled = !isProviderEnabled(state.config, pk)
        saveConfig(state.config)
        return
      }

      if (key.name === 't') {
        // ğŸ“– Test the selected provider's key (fires a real ping)
        const pk = providerKeys[state.settingsCursor]
        testProviderKey(pk)
        return
      }

      if (key.ctrl && key.name === 'c') { exit(0); return }
      return // ğŸ“– Swallow all other keys while settings is open
    }

    // ğŸ“– P key: open settings screen
    if (key.name === 'p') {
      state.settingsOpen = true
      state.settingsCursor = 0
      state.settingsEditMode = false
      state.settingsEditBuffer = ''
      return
    }

    // ğŸ“– Sorting keys: R=rank, Y=tier, O=origin, M=model, L=latest ping, A=avg ping, S=SWE-bench, C=context, H=health, V=verdict, U=uptime
    // ğŸ“– T is reserved for tier filter cycling â€” tier sort moved to Y
    // ğŸ“– N is now reserved for origin filter cycling
    const sortKeys = {
      'r': 'rank', 'y': 'tier', 'o': 'origin', 'm': 'model',
      'l': 'ping', 'a': 'avg', 's': 'swe', 'c': 'ctx', 'h': 'condition', 'v': 'verdict', 'u': 'uptime'
    }

    if (sortKeys[key.name] && !key.ctrl) {
      const col = sortKeys[key.name]
      // ğŸ“– Toggle direction if same column, otherwise reset to asc
      if (state.sortColumn === col) {
        state.sortDirection = state.sortDirection === 'asc' ? 'desc' : 'asc'
      } else {
        state.sortColumn = col
        state.sortDirection = 'asc'
      }
      // ğŸ“– Recompute visible sorted list and reset cursor to top to avoid stale index
      const visible = state.results.filter(r => !r.hidden)
      state.visibleSorted = sortResults(visible, state.sortColumn, state.sortDirection)
      state.cursor = 0
      state.scrollOffset = 0
      return
    }

    // ğŸ“– Interval adjustment keys: W=decrease (faster), X=increase (slower)
    // ğŸ“– Minimum 1s, maximum 60s
    if (key.name === 'w') {
      state.pingInterval = Math.max(1000, state.pingInterval - 1000)
    } else if (key.name === 'x') {
      state.pingInterval = Math.min(60000, state.pingInterval + 1000)
    }

    // ğŸ“– Tier toggle key: T = cycle through each individual tier (All â†’ S+ â†’ S â†’ A+ â†’ A â†’ A- â†’ B+ â†’ B â†’ C â†’ All)
    if (key.name === 't') {
      tierFilterMode = (tierFilterMode + 1) % TIER_CYCLE.length
      applyTierFilter()
      // ğŸ“– Recompute visible sorted list and reset cursor to avoid stale index into new filtered set
      const visible = state.results.filter(r => !r.hidden)
      state.visibleSorted = sortResults(visible, state.sortColumn, state.sortDirection)
      state.cursor = 0
      state.scrollOffset = 0
      return
    }

    // ğŸ“– Origin filter key: N = cycle through each provider (All â†’ NIM â†’ Groq â†’ ... â†’ All)
    if (key.name === 'n') {
      originFilterMode = (originFilterMode + 1) % ORIGIN_CYCLE.length
      applyTierFilter()
      // ğŸ“– Recompute visible sorted list and reset cursor to avoid stale index into new filtered set
      const visible = state.results.filter(r => !r.hidden)
      state.visibleSorted = sortResults(visible, state.sortColumn, state.sortDirection)
      state.cursor = 0
      state.scrollOffset = 0
      return
    }

    // ğŸ“– Help overlay key: K = toggle help overlay
    if (key.name === 'k') {
      state.helpVisible = !state.helpVisible
      return
    }

    // ğŸ“– Mode toggle key: Z = cycle through modes (CLI â†’ Desktop â†’ OpenClaw)
    if (key.name === 'z') {
      const modeOrder = ['opencode', 'opencode-desktop', 'openclaw']
      const currentIndex = modeOrder.indexOf(state.mode)
      const nextIndex = (currentIndex + 1) % modeOrder.length
      state.mode = modeOrder[nextIndex]
      return
    }

    if (key.name === 'x') {
      state.pingInterval = Math.min(60000, state.pingInterval + 1000)
      return
    }

    if (key.name === 'up') {
      if (state.cursor > 0) {
        state.cursor--
        adjustScrollOffset(state)
      }
      return
    }

    if (key.name === 'down') {
      if (state.cursor < state.visibleSorted.length - 1) {
        state.cursor++
        adjustScrollOffset(state)
      }
      return
    }

    if (key.name === 'c' && key.ctrl) { // Ctrl+C
      exit(0)
      return
    }

    if (key.name === 'return') { // Enter
      // ğŸ“– Use the cached visible+sorted array â€” guaranteed to match what's on screen
      const selected = state.visibleSorted[state.cursor]
      if (!selected) return // ğŸ“– Guard: empty visible list (all filtered out)
      // ğŸ“– Allow selecting ANY model (even timeout/down) - user knows what they're doing
      userSelected = { modelId: selected.modelId, label: selected.label, tier: selected.tier, providerKey: selected.providerKey }

      // ğŸ“– Stop everything and act on selection immediately
      clearInterval(ticker)
      clearTimeout(state.pingIntervalObj)
      readline.emitKeypressEvents(process.stdin)
      process.stdin.setRawMode(true)
      process.stdin.pause()
      process.stdin.removeListener('keypress', onKeyPress)
      process.stdout.write(ALT_LEAVE)

      // ğŸ“– Show selection with status
      if (selected.status === 'timeout') {
        console.log(chalk.yellow(`  âš  Selected: ${selected.label} (currently timing out)`))
      } else if (selected.status === 'down') {
        console.log(chalk.red(`  âš  Selected: ${selected.label} (currently down)`))
      } else {
        console.log(chalk.cyan(`  âœ“ Selected: ${selected.label}`))
      }
      console.log()

      // ğŸ“– Warn if no API key is configured for the selected model's provider
      if (state.mode !== 'openclaw') {
        const selectedApiKey = getApiKey(state.config, selected.providerKey)
        if (!selectedApiKey) {
          console.log(chalk.yellow(`  Warning: No API key configured for ${selected.providerKey}.`))
          console.log(chalk.yellow(`  OpenCode may not be able to use ${selected.label}.`))
          console.log(chalk.dim(`  Set ${ENV_VAR_NAMES[selected.providerKey] || selected.providerKey.toUpperCase() + '_API_KEY'} or configure via settings (P key).`))
          console.log()
        }
      }

      // ğŸ“– Dispatch to the correct integration based on active mode
      if (state.mode === 'openclaw') {
        await startOpenClaw(userSelected, apiKey)
      } else if (state.mode === 'opencode-desktop') {
        await startOpenCodeDesktop(userSelected, state.config)
      } else {
        await startOpenCode(userSelected, state.config)
      }
      process.exit(0)
    }
  }

  // ğŸ“– Enable keypress events on stdin
  readline.emitKeypressEvents(process.stdin)
  if (process.stdin.isTTY) {
    process.stdin.setRawMode(true)
  }

  process.stdin.on('keypress', onKeyPress)

  // ğŸ“– Animation loop: render settings overlay OR main table based on state
  const ticker = setInterval(() => {
    state.frame++
    // ğŸ“– Cache visible+sorted models each frame so Enter handler always matches the display
    if (!state.settingsOpen) {
      const visible = state.results.filter(r => !r.hidden)
      state.visibleSorted = sortResults(visible, state.sortColumn, state.sortDirection)
    }
    const content = state.settingsOpen
      ? renderSettings()
      : state.helpVisible
        ? renderHelp()
        : renderTable(state.results, state.pendingPings, state.frame, state.cursor, state.sortColumn, state.sortDirection, state.pingInterval, state.lastPingTime, state.mode, tierFilterMode, state.scrollOffset, state.terminalRows, originFilterMode)
    process.stdout.write(ALT_HOME + content)
  }, Math.round(1000 / FPS))

  // ğŸ“– Populate visibleSorted before the first frame so Enter works immediately
  const initialVisible = state.results.filter(r => !r.hidden)
  state.visibleSorted = sortResults(initialVisible, state.sortColumn, state.sortDirection)

  process.stdout.write(ALT_HOME + renderTable(state.results, state.pendingPings, state.frame, state.cursor, state.sortColumn, state.sortDirection, state.pingInterval, state.lastPingTime, state.mode, tierFilterMode, state.scrollOffset, state.terminalRows, originFilterMode))

  // â”€â”€ Continuous ping loop â€” ping all models every N seconds forever â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

  // ğŸ“– Single ping function that updates result
  // ğŸ“– Uses per-provider API key and URL from sources.js
  // ğŸ“– If no API key is configured, pings without auth â€” a 401 still tells us latency + server is up
  const pingModel = async (r) => {
    const providerApiKey = getApiKey(state.config, r.providerKey) ?? null
    const providerUrl = sources[r.providerKey]?.url ?? sources.nvidia.url
    const { code, ms } = await ping(providerApiKey, r.modelId, providerUrl)

    // ğŸ“– Store ping result as object with ms and code
    // ğŸ“– ms = actual response time (even for errors like 429)
    // ğŸ“– code = HTTP status code ('200', '429', '500', '000' for timeout)
    r.pings.push({ ms, code })

    // ğŸ“– Update status based on latest ping
    if (code === '200') {
      r.status = 'up'
    } else if (code === '000') {
      r.status = 'timeout'
    } else if (code === '401') {
      // ğŸ“– 401 = server is reachable but no API key set (or wrong key)
      // ğŸ“– Treated as 'noauth' â€” server is UP, latency is real, just needs a key
      r.status = 'noauth'
      r.httpCode = code
    } else {
      r.status = 'down'
      r.httpCode = code
    }
  }

  // ğŸ“– Initial ping of all models
  const initialPing = Promise.all(state.results.map(r => pingModel(r)))

  // ğŸ“– Continuous ping loop with dynamic interval (adjustable with W/X keys)
  const schedulePing = () => {
    state.pingIntervalObj = setTimeout(async () => {
      state.lastPingTime = Date.now()

      state.results.forEach(r => {
        pingModel(r).catch(() => {
          // Individual ping failures don't crash the loop
        })
      })

      // ğŸ“– Schedule next ping with current interval
      schedulePing()
    }, state.pingInterval)
  }

  // ğŸ“– Start the ping loop
  state.pingIntervalObj = null
  schedulePing()

  await initialPing

  // ğŸ“– Keep interface running forever - user can select anytime or Ctrl+C to exit
  // ğŸ“– The pings continue running in background with dynamic interval
  // ğŸ“– User can press W to decrease interval (faster pings) or X to increase (slower)
  // ğŸ“– Current interval shown in header: "next ping Xs"
}

main().catch((err) => {
  process.stdout.write(ALT_LEAVE)
  console.error(err)
  process.exit(1)
})
